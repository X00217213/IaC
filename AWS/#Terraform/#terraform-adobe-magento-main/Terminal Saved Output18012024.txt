Last login: Thu Jan 18 08:31:02 on ttys000
complete:13: command not found: compdef
markusburg@computer ~ % whereis terragrunt
terragrunt:
markusburg@computer ~ % terragrunt run-all apply
zsh: command not found: terragrunt
markusburg@computer ~ % tgswitch use 0.19                                                      
✔ 0.19.0 *recent
Installing terragrunt at /Users/markusburg/bin
Switched terragrunt to version "0.19.0" 
markusburg@computer ~ % tfswitch use 0.12                                                      
✔ 1.2.0 *recent
Installing terraform at /Users/markusburg/bin
Switched terraform to version "1.2.0" 
markusburg@computer ~ % terragrunt run-all apply
zsh: command not found: terragrunt
markusburg@computer ~ % $ echo 'export PATH="$HOME/.tgenv/bin:$PATH"' >> ~/.bash_profile
zsh: command not found: $
markusburg@computer ~ % echo 'export PATH="$HOME/.tgenv/bin:$PATH"' >> ~/.bash_profile 
markusburg@computer ~ % terragrunt run-all apply                                        
zsh: command not found: terragrunt
markusburg@computer ~ % ls /usr/local/bin
com.docker.cli			docker-credential-osxkeychain	pfloggerd			prlctl				warp-diag
docker				docker-index			prl_convert			prlexec
docker-compose			hub-tool			prl_disk_tool			prlsrvctl
docker-credential-desktop	kubectl				prl_perf_ctl			warp-cli
docker-credential-ecr-login	kubectl.docker			prlcore2dmp			warp-dex
markusburg@computer ~ % $ echo 'export PATH="$HOME/.tfenv/bin:$PATH"' >> ~/.zprofile
zsh: command not found: $
markusburg@computer ~ % echo 'export PATH="$HOME/.tfenv/bin:$PATH"' >> ~/.zprofile 
markusburg@computer ~ % terragrunt run-all apply                                    
zsh: command not found: terragrunt
markusburg@computer ~ % cd /usr/local/bin/                                              
markusburg@computer bin % ls
com.docker.cli			docker-credential-osxkeychain	pfloggerd			prlctl				warp-diag
docker				docker-index			prl_convert			prlexec
docker-compose			hub-tool			prl_disk_tool			prlsrvctl
docker-credential-desktop	kubectl				prl_perf_ctl			warp-cli
docker-credential-ecr-login	kubectl.docker			prlcore2dmp			warp-dex
markusburg@computer bin % ls -lisa
total 696
 135975   0 drwxr-xr-x  23 root  wheel     736 14 Jan 19:54 .
 100073   0 drwxr-xr-x   4 root  wheel     128 20 Dec 06:51 ..
2540565   0 lrwxr-xr-x   1 root  wheel      62 14 Jan 19:54 com.docker.cli -> /Applications/Docker.app/Contents/Resources/bin/com.docker.cli
2540564   0 lrwxr-xr-x   1 root  wheel      54 14 Jan 19:54 docker -> /Applications/Docker.app/Contents/Resources/bin/docker
2540566   0 lrwxr-xr-x   1 root  wheel      62 14 Jan 19:54 docker-compose -> /Applications/Docker.app/Contents/Resources/bin/docker-compose
2540569   0 lrwxr-xr-x   1 root  wheel      73 14 Jan 19:54 docker-credential-desktop -> /Applications/Docker.app/Contents/Resources/bin/docker-credential-desktop
2540571   0 lrwxr-xr-x   1 root  wheel      75 14 Jan 19:54 docker-credential-ecr-login -> /Applications/Docker.app/Contents/Resources/bin/docker-credential-ecr-login
2540570   0 lrwxr-xr-x   1 root  wheel      77 14 Jan 19:54 docker-credential-osxkeychain -> /Applications/Docker.app/Contents/Resources/bin/docker-credential-osxkeychain
2540568   0 lrwxr-xr-x   1 root  wheel      60 14 Jan 19:54 docker-index -> /Applications/Docker.app/Contents/Resources/bin/docker-index
2540567   0 lrwxr-xr-x   1 root  wheel      56 14 Jan 19:54 hub-tool -> /Applications/Docker.app/Contents/Resources/bin/hub-tool
2540572   0 lrwxr-xr-x   1 root  wheel      55 14 Jan 19:54 kubectl -> /Applications/Docker.app/Contents/Resources/bin/kubectl
2540573   0 lrwxr-xr-x   1 root  wheel      55 14 Jan 19:54 kubectl.docker -> /Applications/Docker.app/Contents/Resources/bin/kubectl
2232999 696 -rwxr-xr-x@  1 root  wheel  353504 30 Jun  2023 pfloggerd
 427708   0 lrwxr-xr-x@  1 root  wheel      68 20 Dec 10:05 prl_convert -> /Applications/Parallels Desktop.app/Contents/MacOS/parallels_wrapper
 427703   0 lrwxr-xr-x@  1 root  wheel      68 20 Dec 10:05 prl_disk_tool -> /Applications/Parallels Desktop.app/Contents/MacOS/parallels_wrapper
 427706   0 lrwxr-xr-x@  1 root  wheel      68 20 Dec 10:05 prl_perf_ctl -> /Applications/Parallels Desktop.app/Contents/MacOS/parallels_wrapper
 427712   0 lrwxr-xr-x@  1 root  wheel      62 20 Dec 10:05 prlcore2dmp -> /Applications/Parallels Desktop.app/Contents/MacOS/prlcore2dmp
 427700   0 lrwxr-xr-x@  1 root  wheel      68 20 Dec 10:05 prlctl -> /Applications/Parallels Desktop.app/Contents/MacOS/parallels_wrapper
 427710   0 lrwxr-xr-x@  1 root  wheel      58 20 Dec 10:05 prlexec -> /Applications/Parallels Desktop.app/Contents/MacOS/prlexec
 427702   0 lrwxr-xr-x@  1 root  wheel      68 20 Dec 10:05 prlsrvctl -> /Applications/Parallels Desktop.app/Contents/MacOS/parallels_wrapper
2487090   0 lrwxr-xr-x   1 root  wheel      61 14 Jan 12:57 warp-cli -> /Applications/Cloudflare WARP.app/Contents/Resources/warp-cli
2487091   0 lrwxr-xr-x   1 root  wheel      61 14 Jan 12:57 warp-dex -> /Applications/Cloudflare WARP.app/Contents/Resources/warp-dex
2487089   0 lrwxr-xr-x   1 root  wheel      62 14 Jan 12:57 warp-diag -> /Applications/Cloudflare WARP.app/Contents/Resources/warp-diag
markusburg@computer bin % cd /Users/markusburg/TerraformMagentoCloud/cloud/production            
markusburg@computer production % terragrunt run-all apply                                      
zsh: command not found: terragrunt
markusburg@computer production % terragrunt -v           
zsh: command not found: terragrunt
markusburg@computer production % tgswitch use 0.19                                               
✔ 0.19.0 *recent
Installing terragrunt at /Users/markusburg/bin
Switched terragrunt to version "0.19.0" 
markusburg@computer production % terragrunt -v    
zsh: command not found: terragrunt
markusburg@computer production % sudo find / -name terragrunt
Password:
find: /System/Volumes/Data/.Spotlight-V100: No such file or directory
find: /System/Volumes/Data/MobileSoftwareUpdate: No such file or directory
find: /System/Volumes/Data/mnt: No such file or directory
find: /System/Volumes/Data/macOS Install Data: No such file or directory
find: /System/Volumes/Data/.fseventsd: No such file or directory
find: /System/Volumes/Data/.DocumentRevisions-V100: No such file or directory
/System/Volumes/Data/Users/markusburg/bin/terragrunt
/System/Volumes/Data/opt/homebrew/var/homebrew/linked/terragrunt
/System/Volumes/Data/opt/homebrew/opt/terragrunt
/System/Volumes/Data/opt/homebrew/Cellar/terragrunt
/System/Volumes/Data/opt/homebrew/Cellar/terragrunt/0.54.18/bin/terragrunt
find: /System/Volumes/Data/.PreviousSystemInformation: No such file or directory
find: /System/Volumes/Data/.TemporaryItems: No such file or directory
find: /System/Volumes/iSCPreboot: No such file or directory
find: /System/DriverKit: No such file or directory
/Users/markusburg/bin/terragrunt
/opt/homebrew/var/homebrew/linked/terragrunt
/opt/homebrew/opt/terragrunt
/opt/homebrew/Cellar/terragrunt
/opt/homebrew/Cellar/terragrunt/0.54.18/bin/terragrunt
find: /dev/fd/3: Not a directory
find: /dev/fd/4: Not a directory
find: /dev/fd/6: Not a directory
markusburg@computer production % export AWS_DEFAULT_REGION=eu-west-1                                    
markusburg@computer production % export AWS_ACCESS_KEY_ID="AKIAWYELJ4WJTLRM4Z4W"                        
markusburg@computer production % export AWS_SECRET_ACCESS_KEY="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"
markusburg@computer production % /opt/homebrew/var/homebrew/linked/terragrunt run-all apply
zsh: permission denied: /opt/homebrew/var/homebrew/linked/terragrunt
markusburg@computer production % sudo /opt/homebrew/var/homebrew/linked/terragrunt run-all apply
sudo: /opt/homebrew/var/homebrew/linked/terragrunt: command not found
markusburg@computer production % /Users/markusburg/bin/terragrunt run-all apply
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % /opt/homebrew/opt/terragrunt run-all apply
zsh: permission denied: /opt/homebrew/opt/terragrunt
markusburg@computer production % /opt/homebrew/Cellar/terragrunt run-all apply
zsh: permission denied: /opt/homebrew/Cellar/terragrunt
markusburg@computer production % ln -s /usr/local/Cellar/tgenv/bin/* /usr/local/bin
zsh: no matches found: /usr/local/Cellar/tgenv/bin/*
markusburg@computer production % ln -s /usr/local/Cellar/tgswitch/bin/* /usr/local/bin
zsh: no matches found: /usr/local/Cellar/tgswitch/bin/*
markusburg@computer production % ln -s /usr/local/Cellar/terragrunt/bin/* /usr/local/bin
zsh: no matches found: /usr/local/Cellar/terragrunt/bin/*
markusburg@computer production % ln -s /usr/local/Cellar/terragrunt /usr/local/bin 
ln: /usr/local/bin/terragrunt: Permission denied
markusburg@computer production % terragrunt -v                                        
zsh: command not found: terragrunt
markusburg@computer production % terragrunt run-all apply                             
zsh: command not found: terragrunt
markusburg@computer production % export PATH=$PATH:/Users/markusburg/bin
markusburg@computer production % terragrunt run-all apply               
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % ls
adminwebnode-asg			magento-cloud				ssh22-securitygroup			varnishnode-securitygroup
aws-data				mysql					terragrunt.hcl				webnode-asg
loadbalancer-internal-securitygroup	mysql-rds-securitygroup			varnish-loadbalanser			webnode-loadbalancer
loadbalancer-internet-securitygroup	redis-securitygroup			varnishcacheproxynode-asg		webnode-securitygroup
markusburg@computer production % pwd
/Users/markusburg/TerraformMagentoCloud/cloud/production
markusburg@computer production % terragrunt -v                                        
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % tgswitch use 0.19                                    
✔ 0.19.0 *recent
Installing terragrunt at /Users/markusburg/bin
Switched terragrunt to version "0.19.0" 
markusburg@computer production % tfswitch use 0.12                                               
✔ 1.2.0 *recent
Installing terraform at /Users/markusburg/bin
Switched terraform to version "1.2.0" 
markusburg@computer production % terragrunt run-all apply
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % cd /Users/markusburg/bin/          
markusburg@computer bin % ls -lisa
total 0
3297610 0 drwxr-xr-x   4 markusburg  staff   128 18 Jan 14:18 .
  26301 0 drwxr-x---+ 34 markusburg  staff  1088 18 Jan 14:15 ..
3324440 0 lrwxr-xr-x   1 markusburg  staff    53 18 Jan 14:18 terraform -> /Users/markusburg/.terraform.versions/terraform_1.2.0
3324437 0 lrwxr-xr-x   1 markusburg  staff    56 18 Jan 14:18 terragrunt -> /Users/markusburg/.terragrunt.versions/terragrunt_0.19.0
markusburg@computer bin % cd /Users/markusburg/.terraform.versions/terraform_1.2.0
cd: not a directory: /Users/markusburg/.terraform.versions/terraform_1.2.0
markusburg@computer bin % ls
terraform	terragrunt
markusburg@computer bin % ls -lisa
total 0
3297610 0 drwxr-xr-x   4 markusburg  staff   128 18 Jan 14:18 .
  26301 0 drwxr-x---+ 34 markusburg  staff  1088 18 Jan 14:15 ..
3324440 0 lrwxr-xr-x   1 markusburg  staff    53 18 Jan 14:18 terraform -> /Users/markusburg/.terraform.versions/terraform_1.2.0
3324437 0 lrwxr-xr-x   1 markusburg  staff    56 18 Jan 14:18 terragrunt -> /Users/markusburg/.terragrunt.versions/terragrunt_0.19.0
markusburg@computer bin % pwd
/Users/markusburg/bin
markusburg@computer bin % cd /Users/markusburg/.terraform.versions/terraform_1.2.0
cd: not a directory: /Users/markusburg/.terraform.versions/terraform_1.2.0
markusburg@computer bin % cd /Users/markusburg/.terraform.versions/               
markusburg@computer .terraform.versions % ls
RECENT		terraform_1.2.0
markusburg@computer .terraform.versions % ls -lisa
total 135440
3297340      0 drwxr-xr-x   4 markusburg  staff       128 18 Jan 08:36 .
  26301      0 drwxr-x---+ 34 markusburg  staff      1088 18 Jan 14:15 ..
3297614      8 -rw-r--r--   1 markusburg  staff         6 18 Jan 08:36 RECENT
3297612 135432 -rwxr-xr-x   1 markusburg  staff  69339504 18 Jan 08:36 terraform_1.2.0
markusburg@computer .terraform.versions % export PATH=$PATH:/Users/markusburg/.terraform.versions/
markusburg@computer .terraform.versions % cd /Users/markusburg/TerraformMagentoCloud/cloud/production 
markusburg@computer production % terragrunt run-all apply                                    
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % export TF_VERSION=0.12   
markusburg@computer production % export TG_VERSION=0.19    
markusburg@computer production % terragrunt run-all apply
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % nano .tfswitch.toml
markusburg@computer production % terragrunt run-all apply
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % nano .tfswitch.toml                                         
markusburg@computer production % terraform -v                                                
Terraform v1.2.0
on darwin_arm64

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer production % nano .tfswitch.toml                                         
markusburg@computer production % terragrunt -v      
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % terraform -v       
Terraform v1.2.0
on darwin_arm64

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer production % terragrunt -v
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % tgswitch
Terragrunt version environment variable: 0.19
Invalid terragrunt version format. Format should be #.#.# or #.#.#-@# where # is numbers and @ is word characters. For example, 0.11.7 and 0.11.9-beta1 are valid versions
Version does not exist or invalid terragrunt version format.
 Format should be #.#.# or #.#.#-@# where # are numbers and @ are word characters.
 For example, 0.11.7 and 0.11.9-beta1 are valid versions


Usage: tgswitch [-hv] [-b value] [-c value] [parameters ...]
 -b, --bin=value    Custom binary path. Ex: tgswitch -b
                    /Users/username/bin/terragrunt
 -c, --chdir=value  Switch to a different working directory before executing the
                    given command. Ex: tgswitch --chdir terragrunt dir will run
                    tgswitch in the directory
 -h, --help         displays help message
 -v, --version      displays the version of tgswitch
Supply the terragrunt version as an argument, or choose from a menu
2024/01/18 14:38:22 Args must be a valid terragrunt version
markusburg@computer production % tgswitch =l
zsh: l not found
markusburg@computer production % tgswitch -l
unknown option: -l
Usage: tgswitch [-hv] [-b value] [-c value] [parameters ...]
 -b, --bin=value    Custom binary path. Ex: tgswitch -b
                    /Users/username/bin/terragrunt
 -c, --chdir=value  Switch to a different working directory before executing the
                    given command. Ex: tgswitch --chdir terragrunt dir will run
                    tgswitch in the directory
 -h, --help         displays help message
 -v, --version      displays the version of tgswitch
markusburg@computer production % tgswitch   
Terragrunt version environment variable: 0.19
Invalid terragrunt version format. Format should be #.#.# or #.#.#-@# where # is numbers and @ is word characters. For example, 0.11.7 and 0.11.9-beta1 are valid versions
Version does not exist or invalid terragrunt version format.
 Format should be #.#.# or #.#.#-@# where # are numbers and @ are word characters.
 For example, 0.11.7 and 0.11.9-beta1 are valid versions


Usage: tgswitch [-hv] [-b value] [-c value] [parameters ...]
 -b, --bin=value    Custom binary path. Ex: tgswitch -b
                    /Users/username/bin/terragrunt
 -c, --chdir=value  Switch to a different working directory before executing the
                    given command. Ex: tgswitch --chdir terragrunt dir will run
                    tgswitch in the directory
 -h, --help         displays help message
 -v, --version      displays the version of tgswitch
Supply the terragrunt version as an argument, or choose from a menu
2024/01/18 14:38:47 Args must be a valid terragrunt version
markusburg@computer production % tgswitch -v

Version: 0.6.0
markusburg@computer production % tgswitch 0.19
Invalid terragrunt version format. Format should be #.#.# or #.#.#-@# where # is numbers and @ is word characters. For example, 0.11.7 and 0.11.9-beta1 are valid versions
Args must be a valid terragrunt version


Usage: tgswitch [-hv] [-b value] [-c value] [parameters ...]
 -b, --bin=value    Custom binary path. Ex: tgswitch -b
                    /Users/username/bin/terragrunt
 -c, --chdir=value  Switch to a different working directory before executing the
                    given command. Ex: tgswitch --chdir terragrunt dir will run
                    tgswitch in the directory
 -h, --help         displays help message
 -v, --version      displays the version of tgswitch
Supply the terragrunt version as an argument, or choose from a menu
markusburg@computer production % tgswitch 0.19.0
Installing terragrunt at /Users/markusburg/bin
Switched terragrunt to version "0.19.0" 
markusburg@computer production % terragrunt -v  
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % export TG_VERSION=0.19.0
markusburg@computer production % tgswitch
Terragrunt version environment variable: 0.19.0
Installing terragrunt at /Users/markusburg/bin
Switched terragrunt to version "0.19.0" 
markusburg@computer production % terragrunt -v           
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % nano .tgswitch.toml
markusburg@computer production % nano ~/.tgswitch.toml
markusburg@computer production % terragrunt -v        
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % tgswitch -b /Users/markusburg/bin/terragrunt 0.19.0
Reading configuration from home directory for .tgswitch.toml
Switched terragrunt to version "0.19.0" 
markusburg@computer production % terragrunt -v                                      
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % brew upgrade warrensbox/tap/tgswitch
Warning: warrensbox/tap/tgswitch 0.6.0 already installed
markusburg@computer production % brew uninstall warrensbox/tap/tgswitch

Uninstalling /opt/homebrew/Cellar/tgswitch/0.6.0... (6 files, 9.3MB)
markusburg@computer production % brew upgrade warrensbox/tap/tgswitch  
Error: warrensbox/tap/tgswitch not installed
markusburg@computer production % brew install warrensbox/tap/tgswitch
==> Fetching warrensbox/tap/tgswitch
==> Downloading https://github.com/warrensbox/tgswitch/releases/download/0.6.0/tgswitch_0.6.0_darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/18bb6d6cbc49c735e87571191fb234c586bdb6e97f296a23686751ff5abf6481--tgswitch_0.6.0_darwin_arm64.tar.gz
==> Installing tgswitch from warrensbox/tap
==> Downloading https://formulae.brew.sh/api/formula.jws.json
################################################################################################################################################################# 100.0%
==> Downloading https://formulae.brew.sh/api/cask.jws.json
################################################################################################################################################################# 100.0%
==> Caveats
Type 'tgswitch' on your command line and choose the terragrunt version that you want from the dropdown. This command currently only works on MacOs and Linux
==> Summary
🍺  /opt/homebrew/Cellar/tgswitch/0.6.0: 6 files, 9.3MB, built in 1 second
==> Running `brew cleanup tgswitch`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer production % terragrunt -v                         
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer production % brew uninstall warrensbox/tap/tgswitch

Uninstalling /opt/homebrew/Cellar/tgswitch/0.6.0... (6 files, 9.3MB)
markusburg@computer production % brew install warrensbox/tap/tgswitch 0.5.0
Warning: No available formula with the name "0.5.0".
==> Searching for similarly named formulae and casks...
Error: No formulae or casks found for 0.5.0.
markusburg@computer production % brew install warrensbox/tap/tgswitch 0.5  
Warning: No available formula with the name "0.5".
==> Searching for similarly named formulae and casks...
==> Formulae
mariadb@10.5

To install mariadb@10.5, run:
  brew install mariadb@10.5
markusburg@computer production % brew list --versions warrensbox/tap/tgswitch
markusburg@computer production % brew search warrensbox/tap/tgswitch
==> Formulae
tgswitch
markusburg@computer production % brew info warrensbox/tap/tgswitch
==> warrensbox/tap/tgswitch: stable 0.6.0
The tgswitch command lets you switch between terragrunt versions.
https://warrensbox.github.io/tgswitch
Not installed
From: https://github.com/warrensbox/homebrew-tap/blob/HEAD/Formula/tgswitch.rb
==> Caveats
Type 'tgswitch' on your command line and choose the terragrunt version that you want from the dropdown. This command currently only works on MacOs and Linux
markusburg@computer production % brew versions warrensbox/tap/tgswitch
Error: Unknown command: versions
markusburg@computer production % find /usr/local/Homebrew/ -type d -name "tgswitch" -exec ls -1 {} \;
find: /usr/local/Homebrew/: No such file or directory
markusburg@computer production % brew install warrensbox/tap/tgswitch 0.5.393            
==> Downloading https://formulae.brew.sh/api/formula.jws.json

==> Downloading https://formulae.brew.sh/api/cask.jws.json

Warning: No available formula with the name "0.5.393".
==> Searching for similarly named formulae and casks...
Error: No formulae or casks found for 0.5.393.
markusburg@computer production % brew install warrensbox/tap/tgswitch.0.5.393
Warning: No available formula or cask with the name "warrensbox/tap/tgswitch.0.5.393". Did you mean warrensbox/tap/tgswitch?
markusburg@computer production % brew install warrensbox/tap/tgswitch_0.5.393
Warning: No available formula or cask with the name "warrensbox/tap/tgswitch_0.5.393". Did you mean warrensbox/tap/tgswitch?
markusburg@computer production % cd /Users/markusburg 
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_mac_arm64"
zsh: command not found: wget
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_arm64"
zsh: command not found: wget
markusburg@computer ~ % brew install warrensbox/tap/tgswitch                                                                         
==> Fetching warrensbox/tap/tgswitch
==> Downloading https://github.com/warrensbox/tgswitch/releases/download/0.6.0/tgswitch_0.6.0_darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/18bb6d6cbc49c735e87571191fb234c586bdb6e97f296a23686751ff5abf6481--tgswitch_0.6.0_darwin_arm64.tar.gz
==> Installing tgswitch from warrensbox/tap
==> Downloading https://formulae.brew.sh/api/formula.jws.json

==> Downloading https://formulae.brew.sh/api/cask.jws.json

==> Caveats
Type 'tgswitch' on your command line and choose the terragrunt version that you want from the dropdown. This command currently only works on MacOs and Linux
==> Summary
🍺  /opt/homebrew/Cellar/tgswitch/0.6.0: 6 files, 9.3MB, built in 1 second
==> Running `brew cleanup tgswitch`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer ~ % terragrunt -v                                                                                                
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer ~ % tgswitch 0.19.0                                                        
Reading configuration from home directory for .tgswitch.toml
Switched terragrunt to version "0.19.0" 
markusburg@computer ~ % terragrunt -v  
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_386"  
zsh: command not found: wget
markusburg@computer ~ % terragrunt -v                                                                                                
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer ~ % brew uninstall warrensbox/tap/tgswitch                                                                       

Uninstalling /opt/homebrew/Cellar/tgswitch/0.6.0... (6 files, 9.3MB)
markusburg@computer ~ % terragrunt -v                         
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer ~ % tgswitch -b /Users/markusburg/bin/terragrunt 0.19.0
zsh: command not found: tgswitch
markusburg@computer ~ % brew install warrensbox/tap/tgswitch                                                                                   
==> Fetching warrensbox/tap/tgswitch
==> Downloading https://github.com/warrensbox/tgswitch/releases/download/0.6.0/tgswitch_0.6.0_darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/18bb6d6cbc49c735e87571191fb234c586bdb6e97f296a23686751ff5abf6481--tgswitch_0.6.0_darwin_arm64.tar.gz
==> Installing tgswitch from warrensbox/tap
==> Downloading https://formulae.brew.sh/api/formula.jws.json

==> Downloading https://formulae.brew.sh/api/cask.jws.json

==> Caveats
Type 'tgswitch' on your command line and choose the terragrunt version that you want from the dropdown. This command currently only works on MacOs and Linux
==> Summary
🍺  /opt/homebrew/Cellar/tgswitch/0.6.0: 6 files, 9.3MB, built in 1 second
==> Running `brew cleanup tgswitch`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer ~ % tgswitch -b /Users/markusburg/bin/terragrunt_darwin_386 0.19.0 
Reading configuration from home directory for .tgswitch.toml
2024/01/18 15:19:19 
		Unable to create new symlink.
		Maybe symlink already exist. Try removing existing symlink manually.
		Try running "unlink" to remove existing symlink.
		If error persist, you may not have the permission to create a symlink at /Users/markusburg/bin/terragrunt_darwin_386
		Error: symlink /Users/markusburg/.terragrunt.versions/terragrunt_0.19.0 /Users/markusburg/bin/terragrunt_darwin_386: file exists
		
markusburg@computer ~ % sudo tgswitch -b /Users/markusburg/bin/terragrunt_darwin_386 0.19.0
Password:
Reading configuration from home directory for .tgswitch.toml
2024/01/18 15:19:42 Creating directory for terragrunt: /var/root/.terragrunt.versions/
Downloading https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_arm64 to terragrunt_darwin_arm64
Downloading ...
230306 bytes downloaded.
2024/01/18 15:19:43 
		Unable to create new symlink.
		Maybe symlink already exist. Try removing existing symlink manually.
		Try running "unlink" to remove existing symlink.
		If error persist, you may not have the permission to create a symlink at /Users/markusburg/bin/terragrunt_darwin_386
		Error: symlink /var/root/.terragrunt.versions/terragrunt_0.19.0 /Users/markusburg/bin/terragrunt_darwin_386: file exists
		
markusburg@computer ~ % terragrunt -v                                      
zsh: command not found: terragrunt
markusburg@computer ~ % tgswitch 0.19.0                                                    
Reading configuration from home directory for .tgswitch.toml
Switched terragrunt to version "0.19.0" 
markusburg@computer ~ % terragrunt -v  
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer ~ % brew install wget
==> Downloading https://ghcr.io/v2/homebrew/core/wget/manifests/1.21.4
################################################################################################################################################################# 100.0%
==> Fetching dependencies for wget: libunistring, gettext and libidn2
==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.1
################################################################################################################################################################# 100.0%
==> Fetching libunistring
==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/blobs/sha256:6d49946a29c0b11e7c273edcdcff15d90b4d55bd9038e85f83fe7741e035ab28
################################################################################################################################################################# 100.0%
==> Downloading https://ghcr.io/v2/homebrew/core/gettext/manifests/0.22.4
################################################################################################################################################################# 100.0%
==> Fetching gettext
==> Downloading https://ghcr.io/v2/homebrew/core/gettext/blobs/sha256:43d00547f4a1036a642c8a41650b483f0054cd239ab4b9ca171563067c8db264
################################################################################################################################################################# 100.0%
==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.4_1-1
################################################################################################################################################################# 100.0%
==> Fetching libidn2
==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/blobs/sha256:d79edd6e4fa829e8e00f874b362068c67f8f9b4e76e58c8140e5b087ca924553
################################################################################################################################################################# 100.0%
==> Fetching wget
==> Downloading https://ghcr.io/v2/homebrew/core/wget/blobs/sha256:47cb2b77bcb48ee8d8b8fb222bcafe0febe11195ac6476402917da03211412d8
################################################################################################################################################################# 100.0%
==> Installing dependencies for wget: libunistring, gettext and libidn2
==> Installing wget dependency: libunistring
==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.1
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/a34801f1ad5800ba51b2b3951d82a913ccf0641982f86b02df2f0aa182535055--libunistring-1.1.bottle_manifest.json
==> Pouring libunistring--1.1.arm64_sonoma.bottle.tar.gz
🍺  /opt/homebrew/Cellar/libunistring/1.1: 56 files, 5.0MB
==> Installing wget dependency: gettext
==> Downloading https://ghcr.io/v2/homebrew/core/gettext/manifests/0.22.4
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/3ceb9457127eaa7378dd80ed256098ffb391e2350069becb25cfe2a14f0b7d6d--gettext-0.22.4.bottle_manifest.json
==> Pouring gettext--0.22.4.arm64_sonoma.bottle.tar.gz
🍺  /opt/homebrew/Cellar/gettext/0.22.4: 2,042 files, 24.3MB
==> Installing wget dependency: libidn2
==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.4_1-1
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/03ad193177f4e7d05ee2ed19a455028cb5fbf7ea1a812d88f18f5e9e8b4a4d43--libidn2-2.3.4_1-1.bottle_manifest.json
==> Pouring libidn2--2.3.4_1.arm64_sonoma.bottle.1.tar.gz
🍺  /opt/homebrew/Cellar/libidn2/2.3.4_1: 79 files, 1MB
==> Installing wget
==> Pouring wget--1.21.4.arm64_sonoma.bottle.tar.gz
🍺  /opt/homebrew/Cellar/wget/1.21.4: 91 files, 4.4MB
==> Running `brew cleanup wget`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer ~ % brew uninstall warrensbox/tap/tgswitch             

Uninstalling /opt/homebrew/Cellar/tgswitch/0.6.0... (6 files, 9.3MB)
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_arm64"
/bin/terragrunt: Read-only file system
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_arm64"
/bin/terragrunt: Read-only file system
markusburg@computer ~ % sudo wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_arm64"
/bin/terragrunt: Read-only file system
markusburg@computer ~ % chmod +x /bin/terragrunt
chmod: /bin/terragrunt: No such file or directory
markusburg@computer ~ % mkdir /bin/terragrunt
mkdir: /bin/terragrunt: Read-only file system
markusburg@computer ~ % cd bin 
markusburg@computer bin % mkdir /terragrunt 
mkdir: /terragrunt: Read-only file system
markusburg@computer bin % ls
terraform	terragrunt
markusburg@computer bin % mkdir /terragrunt
mkdir: /terragrunt: Read-only file system
markusburg@computer bin % mkdir terragrunt 
markusburg@computer bin % cd ..            
markusburg@computer ~ % pwd             
/Users/markusburg
markusburg@computer ~ % sudo wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_arm64"
/bin/terragrunt: Read-only file system
markusburg@computer ~ % chmod +x /bin/terragrunt                                                                                                      
chmod: /bin/terragrunt: No such file or directory
markusburg@computer ~ % sudo wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_linux_arm64" 
/bin/terragrunt: Read-only file system
markusburg@computer ~ % brew uninstall warrensbox/tap/tgswitch                                                                                        

Error: No available formula or cask with the name "warrensbox/tap/tgswitch". Did you mean warrensbox/tap/tfswitch or warrensbox/tap/jscheck?
markusburg@computer ~ % brew install terragrunt 0.19                                                                                                 
==> Downloading https://formulae.brew.sh/api/formula.jws.json
##O=#     #                                                                                                                                                            
==> Downloading https://formulae.brew.sh/api/cask.jws.json

Warning: No available formula with the name "0.19".
==> Searching for similarly named formulae and casks...
==> Formulae
thrift@0.19

To install thrift@0.19, run:
  brew install thrift@0.19
markusburg@computer ~ % brew install terragrunt@0.19
Warning: No available formula with the name "terragrunt@0.19". Did you mean terragrunt?
==> Searching for similarly named formulae and casks...
==> Formulae
terragrunt ✔

To install terragrunt ✔, run:
  brew install terragrunt ✔
markusburg@computer ~ % brew install terragrunt@0.19.0
Warning: No available formula with the name "terragrunt@0.19.0". Did you mean terragrunt?
==> Searching for similarly named formulae and casks...
==> Formulae
terragrunt ✔

To install terragrunt ✔, run:
  brew install terragrunt ✔
markusburg@computer ~ % git clone https://github.com/cunymatthieu/tgenv.git /usr/local/Cellar/tgenv
fatal: could not create leading directories of '/usr/local/Cellar/tgenv': Permission denied
markusburg@computer ~ % cd /usr/local/Cellar/tgenv
cd: no such file or directory: /usr/local/Cellar/tgenv
markusburg@computer ~ % mkdir /usr/local/Cellar/tgenv
mkdir: /usr/local/Cellar: No such file or directory
markusburg@computer ~ % cd /usr/local/  
markusburg@computer local % ls
bin	share
markusburg@computer local % sudo / -name Cellar
Password:
sudo: /: command not found
markusburg@computer local % sudo find / -name Cellar
find: /System/Volumes/Data/.Spotlight-V100: No such file or directory
find: /System/Volumes/Data/MobileSoftwareUpdate: No such file or directory
find: /System/Volumes/Data/mnt: No such file or directory
find: /System/Volumes/Data/macOS Install Data: No such file or directory
find: /System/Volumes/Data/.fseventsd: No such file or directory
find: /System/Volumes/Data/.DocumentRevisions-V100: No such file or directory
/System/Volumes/Data/opt/homebrew/Cellar
find: /System/Volumes/Data/.PreviousSystemInformation: No such file or directory
find: /System/Volumes/Data/.TemporaryItems: No such file or directory
find: /System/Volumes/iSCPreboot: No such file or directory
find: /System/DriverKit: No such file or directory
/opt/homebrew/Cellar
find: /dev/fd/3: Not a directory
find: /dev/fd/4: Not a directory
find: /dev/fd/6: Not a directory
markusburg@computer local % cd /opt/homebrew/Cellar
markusburg@computer Cellar % ls
ca-certificates			libyaml				python-distlib			pyyaml				tfswitch
gettext				m1-terraform-provider-helper	python-filelock			readline			virtualenv
go				mpdecimal			python-platformdirs		sqlite				wget
libidn2				openssl@3			python-setuptools		terraform			xz
libunistring			pre-commit			python@3.12			terragrunt
markusburg@computer Cellar % cd /bin/
markusburg@computer /bin % pwd
/bin
markusburg@computer /bin % cd /Users/markusburg                                                                                                     
markusburg@computer ~ % tgenv
zsh: command not found: tgenv
markusburg@computer ~ % brew install tgenv
==> Downloading https://formulae.brew.sh/api/formula.jws.json

==> Downloading https://formulae.brew.sh/api/cask.jws.json

==> Downloading https://ghcr.io/v2/homebrew/core/tgenv/manifests/0.0.3
################################################################################################################################################################# 100.0%
==> Fetching tgenv
==> Downloading https://ghcr.io/v2/homebrew/core/tgenv/blobs/sha256:ceef88ef9082c454a7f9cb0b6833b0a1b3df5147d46cb658a485659ecc081c60
################################################################################################################################################################# 100.0%
Error: Cannot install tgenv because conflicting formulae are installed.
  terragrunt: because tgenv symlinks terragrunt binaries

Please `brew unlink terragrunt` before continuing.

Unlinking removes a formula's symlinks from /opt/homebrew. You can
link the formula again after the install finishes. You can --force this
install, but the build may fail or cause obscure side effects in the
resulting software.
markusburg@computer ~ % brew unlink terragrunt
Unlinking /opt/homebrew/Cellar/terragrunt/0.54.18... 0 symlinks removed.
markusburg@computer ~ % brew install warrensbox/tap/tgswitch                                                                                     
==> Fetching warrensbox/tap/tgswitch
==> Downloading https://github.com/warrensbox/tgswitch/releases/download/0.6.0/tgswitch_0.6.0_darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/18bb6d6cbc49c735e87571191fb234c586bdb6e97f296a23686751ff5abf6481--tgswitch_0.6.0_darwin_arm64.tar.gz
==> Installing tgswitch from warrensbox/tap
==> Caveats
Type 'tgswitch' on your command line and choose the terragrunt version that you want from the dropdown. This command currently only works on MacOs and Linux
==> Summary
🍺  /opt/homebrew/Cellar/tgswitch/0.6.0: 6 files, 9.3MB, built in 1 second
==> Running `brew cleanup tgswitch`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer ~ % terragrunt -v                                                                                                                 
zsh: command not found: terragrunt
markusburg@computer ~ % tgswitch 0.19.0                                                                                                               
Reading configuration from home directory for .tgswitch.toml
Switched terragrunt to version "0.19.0" 
markusburg@computer ~ % terragrunt -v  
/Users/markusburg/bin/terragrunt: line 7: syntax error near unexpected token `newline'
/Users/markusburg/bin/terragrunt: line 7: `<!DOCTYPE html>'
markusburg@computer ~ % brew uninstall warrensbox/tap/tgswitch                                     

Uninstalling /opt/homebrew/Cellar/tgswitch/0.6.0... (6 files, 9.3MB)
markusburg@computer ~ % brew unlink terragrunt                
Unlinking /opt/homebrew/Cellar/terragrunt/0.54.18... 0 symlinks removed.
markusburg@computer ~ % brew uninstall terragrunt             
Uninstalling /opt/homebrew/Cellar/terragrunt/0.54.18... (5 files, 53.7MB)
markusburg@computer ~ % tgenv install 0.19.0
zsh: command not found: tgenv
markusburg@computer ~ % brew install tgenv                    
==> Downloading https://ghcr.io/v2/homebrew/core/tgenv/manifests/0.0.3
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/b08bee03b42f3adb19c82d3a804686f562c75bdebd7fd077618759cd2a8ac261--tgenv-0.0.3.bottle_manifest.json
==> Fetching tgenv
==> Downloading https://ghcr.io/v2/homebrew/core/tgenv/blobs/sha256:ceef88ef9082c454a7f9cb0b6833b0a1b3df5147d46cb658a485659ecc081c60
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/e3d7d4faf2bba1c52b6faf0a755aca42d577bd1f6e01e9e6a4dedccd07bd0d6f--tgenv--0.0.3.all.bottle.tar.gz
==> Pouring tgenv--0.0.3.all.bottle.tar.gz
🍺  /opt/homebrew/Cellar/tgenv/0.0.3: 18 files, 17.9KB
==> Running `brew cleanup tgenv`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer ~ % tgenv install 0.19.0     
tgenv: tgenv-install: [ERROR] No versions matching '0.19.0' found in remote
markusburg@computer ~ % tgenv install 0.19  
tgenv: tgenv-install: [ERROR] No versions matching '0.19' found in remote
markusburg@computer ~ % tgenv install 0.19.31
tgenv: tgenv-install: [ERROR] No versions matching '0.19.31' found in remote
markusburg@computer ~ % tgenv -v             
tgenv 0.1.0
markusburg@computer ~ % tgenv -h
Usage: tgenv <command> [<options>]

Commands:
   install       Install a specific version of Terragrunt
   use           Switch a version to use
   uninstall     Uninstall a specific version of Terragrunt
   list          List all installed versions
   list-remote   List all installable versions

markusburg@computer ~ % tgenv list
tgenv: tgenv-list: [ERROR] No versions available. Please install one with: tgenv install
markusburg@computer ~ % tgenv -list
no such command '-list'
Usage: tgenv <command> [<options>]

Commands:
   install       Install a specific version of Terragrunt
   use           Switch a version to use
   uninstall     Uninstall a specific version of Terragrunt
   list          List all installed versions
   list-remote   List all installable versions

markusburg@computer ~ % tgenv -list-remote
no such command '-list-remote'
Usage: tgenv <command> [<options>]

Commands:
   install       Install a specific version of Terragrunt
   use           Switch a version to use
   uninstall     Uninstall a specific version of Terragrunt
   list          List all installed versions
   list-remote   List all installable versions

markusburg@computer ~ % tgenv list-remote 
0.54.19
0.54.18
0.54.17
0.54.16
0.54.15
0.54.14
0.54.13
0.54.12
0.54.11
0.54.10
0.54.9
0.54.8
0.54.7
0.54.6
0.54.5
0.54.4
0.54.3
0.54.2
0.54.1
0.54.0
0.53.8
0.53.7
0.53.6
0.53.5
0.53.4
0.53.3
0.53.2
0.53.1
0.53.0
0.52.7
0.52.6
0.52.5
0.52.4
0.52.3
0.52.2
0.52.1
0.52.0
0.51.9
0.51.8
0.51.7
0.51.6
0.51.5
0.51.4
0.51.3
0.51.2
0.51.1
0.51.0
0.50.17
0.50.16
0.50.15
0.50.14
0.50.13
0.50.12
0.50.11
0.50.10
0.50.9
0.50.8
0.50.7
0.50.6
0.50.5
0.50.4
0.50.3
0.50.2
0.50.1
0.50.0
0.49.1
0.49.0
0.48.7
0.48.6
0.48.5
0.48.4
0.48.3
0.48.2
0.48.1
0.48.0
0.47.0
0.46.3
0.46.2
0.46.1
0.46.0
0.45.18
0.45.17
0.45.16
0.45.15
0.45.14
0.45.13
0.45.12
0.45.11
0.45.10
0.45.9
0.45.8
0.45.7
0.45.6
0.45.5
0.45.4
0.45.3
0.45.2
0.45.1
0.45.0
markusburg@computer ~ % tgenv install 0.19.31
tgenv: tgenv-install: [ERROR] No versions matching '0.19.31' found in remote
markusburg@computer ~ % tfenv use 0.19.31
zsh: command not found: tfenv
markusburg@computer ~ % brew uninstall tfenv     
Error: No such keg: /opt/homebrew/Cellar/tfenv
markusburg@computer ~ % brew uninstall tgenv
Uninstalling /opt/homebrew/Cellar/tgenv/0.0.3... (18 files, 17.9KB)
markusburg@computer ~ % pwd                  
/Users/markusburg
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.xx.x/terragrunt_darwin_amd64"

/bin/terragrunt: Read-only file system
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.xx.x/terragrunt_linux_amd64"

/bin/terragrunt: Read-only file system
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_darwin_amd64"

/bin/terragrunt: Read-only file system
markusburg@computer ~ % wget -q -O /bin/terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_linux_amd64"

/bin/terragrunt: Read-only file system
markusburg@computer ~ % sudo mkdir /bin/terragrunt
Password:
mkdir: /bin/terragrunt: Read-only file system
markusburg@computer ~ % wget -q -O /bin/ "https://github.com/gruntwork-io/terragrunt/releases/download/v0.19.0/terragrunt_linux_amd64" 

/bin/: Is a directory
markusburg@computer ~ % sudo cp /Users/markusburg/bin/terragrunt_darwin_amd64 /bin/
cp: /bin/terragrunt_darwin_amd64: Read-only file system
markusburg@computer ~ % sudo cp /Users/markusburg/bin/terragrunt_darwin_amd64 /bin/terragrunt
cp: /bin/terragrunt: Read-only file system
markusburg@computer ~ % chmod +x /Users/markusburg/bin/terragrunt_darwin_amd64
markusburg@computer ~ % sudo cp /Users/markusburg/bin/terragrunt_darwin_amd64 /bin/terragrunt
cp: /bin/terragrunt: Read-only file system
markusburg@computer ~ % terragrunt -v                                                                                                        
terragrunt version v0.19.0
markusburg@computer ~ % terragrunt run-all apply                                    
[terragrunt] [/Users/markusburg] 2024/01/18 17:11:50 Running command: terraform --version
[terragrunt] 2024/01/18 17:11:50 Reading Terragrunt config file at /Users/markusburg/terragrunt.hcl
[terragrunt] 2024/01/18 17:11:50 Error reading file at path /Users/markusburg/terragrunt.hcl: open /Users/markusburg/terragrunt.hcl: no such file or directory
[terragrunt] 2024/01/18 17:11:50 Unable to determine underlying exit code, so Terragrunt will exit with error code 1
markusburg@computer ~ % cd /Users/markusburg/TerraformMagentoCloud/cloud/production 
markusburg@computer production % terragrunt run-all apply                                    
[terragrunt] [/Users/markusburg/TerraformMagentoCloud/cloud/production] 2024/01/18 17:12:18 Running command: terraform --version
[terragrunt] 2024/01/18 17:12:19 Reading Terragrunt config file at /Users/markusburg/TerraformMagentoCloud/cloud/production/terragrunt.hcl
[terragrunt] 2024/01/18 17:12:19 /Users/markusburg/TerraformMagentoCloud/cloud/production/terragrunt.hcl:1,1-7: Unsupported block type; Blocks of type "locals" are not expected here., and 7 other diagnostic(s)
[terragrunt] 2024/01/18 17:12:19 Unable to determine underlying exit code, so Terragrunt will exit with error code 1
markusburg@computer production % terraform --version
Terraform v1.2.0
on darwin_arm64

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer production % pwd
/Users/markusburg/TerraformMagentoCloud/cloud/production
markusburg@computer production % pwd
/Users/markusburg/TerraformMagentoCloud/cloud/production
markusburg@computer production % terragrunt run-all apply
[terragrunt] [/Users/markusburg/TerraformMagentoCloud/cloud/production] 2024/01/18 17:15:31 Running command: terraform --version
[terragrunt] 2024/01/18 17:15:31 Reading Terragrunt config file at /Users/markusburg/TerraformMagentoCloud/cloud/production/terragrunt.hcl
[terragrunt] 2024/01/18 17:15:31 /Users/markusburg/TerraformMagentoCloud/cloud/production/terragrunt.hcl:33,1-9: Unsupported block type; Blocks of type "generate" are not expected here., and 6 other diagnostic(s)
[terragrunt] 2024/01/18 17:15:31 Unable to determine underlying exit code, so Terragrunt will exit with error code 1
markusburg@computer production % brew link terragrunt                                                                                               
Error: No such keg: /opt/homebrew/Cellar/terragrunt
markusburg@computer production % ls -lisa /Users/markusburg/bin 
total 40208
3297610     0 drwxr-xr-x   5 markusburg  staff       160 18 Jan 15:54 .
  26301     0 drwxr-x---+ 35 markusburg  staff      1120 18 Jan 14:42 ..
3332406    16 -rw-r--r--@  1 markusburg  staff      6148 18 Jan 15:54 .DS_Store
3324440     0 lrwxr-xr-x   1 markusburg  staff        53 18 Jan 14:18 terraform -> /Users/markusburg/.terraform.versions/terraform_1.2.0
3342051 40192 -rwxr-xr-x@  1 markusburg  staff  20575288 18 Jan 15:49 terragrunt
markusburg@computer production % nano $HOME/.aws/terraform.tfvars
markusburg@computer production % nano $HOME/.aws/terraform.tfvars
markusburg@computer production % cd /Users/markusburg/TerraformMagentoCloud-minimal/magento-cloud-minimal/production 
markusburg@computer production % terragrunt run-all apply                                                  
[terragrunt] [/Users/markusburg/TerraformMagentoCloud-minimal/magento-cloud-minimal/production] 2024/01/18 19:35:56 Running command: terraform --version
[terragrunt] 2024/01/18 19:35:56 Reading Terragrunt config file at /Users/markusburg/TerraformMagentoCloud-minimal/magento-cloud-minimal/production/terragrunt.hcl
[terragrunt] 2024/01/18 19:35:56 /Users/markusburg/TerraformMagentoCloud-minimal/magento-cloud-minimal/production/terragrunt.hcl:1,1-7: Unsupported block type; Blocks of type "locals" are not expected here., and 7 other diagnostic(s)
[terragrunt] 2024/01/18 19:35:56 Unable to determine underlying exit code, so Terragrunt will exit with error code 1
markusburg@computer production % cd /Users/markusburg/terraform-adobe-magento-main 
markusburg@computer terraform-adobe-magento-main % ls
CODEOWNERS			deploy				modules				terraform-adobe-magento.pem
LICENSE				docs				outputs.tf			test
NOTICE.txt			examples			providers.tf			userdata
README.md			main.tf				setup_workspace			variables.tf
markusburg@computer terraform-adobe-magento-main % terraform login
Terraform will request an API token for app.terraform.io using your browser.

If login is successful, Terraform will store the token in plain text in
the following file for use by subsequent commands:
    /Users/markusburg/.terraform.d/credentials.tfrc.json

Do you want to proceed?
  Only 'yes' will be accepted to confirm.

  Enter a value: yes


---------------------------------------------------------------------------------

Terraform must now open a web browser to the tokens page for app.terraform.io.

If a browser does not open this automatically, open the following URL to proceed:
    https://app.terraform.io/app/settings/tokens?source=terraform-login


---------------------------------------------------------------------------------

Generate a token using your browser, and copy-paste it into this prompt.

Terraform will store the token in plain text in the following file
for use by subsequent commands:
    /Users/markusburg/.terraform.d/credentials.tfrc.json

Token for app.terraform.io:
  Enter a value: 


Retrieved token for user x00217213


---------------------------------------------------------------------------------

                                          -                                
                                          -----                           -
                                          ---------                      --
                                          ---------  -                -----
                                           ---------  ------        -------
                                             -------  ---------  ----------
                                                ----  ---------- ----------
                                                  --  ---------- ----------
   Welcome to Terraform Cloud!                     -  ---------- -------
                                                      ---  ----- ---
   Documentation: terraform.io/docs/cloud             --------   -
                                                      ----------
                                                      ----------
                                                       ---------
                                                           -----
                                                               -


   New to TFC? Follow these steps to instantly apply an example configuration:

   $ git clone https://github.com/hashicorp/tfc-getting-started.git
   $ cd tfc-getting-started
   $ scripts/setup.sh


markusburg@computer terraform-adobe-magento-main % export TERRAFORM_CONFIG="$HOME/.terraform.d/credentials.tfrc.json"
markusburg@computer terraform-adobe-magento-main % cd setup_workspace
markusburg@computer setup_workspace % terraform init
Initializing modules...

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/null v3.2.2

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: org


Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # null_resource.remoteinit will be created
  + resource "null_resource" "remoteinit" {
      + id = (known after apply)
    }

  # null_resource.setup_backend_file will be created
  + resource "null_resource" "setup_backend_file" {
      + id = (known after apply)
    }

  # module.tfcloud.local_file.backend_file will be created
  + resource "local_file" "backend_file" {
      + content              = (known after apply)
      + content_base64sha256 = (known after apply)
      + content_base64sha512 = (known after apply)
      + content_md5          = (known after apply)
      + content_sha1         = (known after apply)
      + content_sha256       = (known after apply)
      + content_sha512       = (known after apply)
      + directory_permission = "0777"
      + file_permission      = "0777"
      + filename             = "backend.hcl"
      + id                   = (known after apply)
    }

  # module.tfcloud.random_string.rand6 will be created
  + resource "random_string" "rand6" {
      + id          = (known after apply)
      + length      = 6
      + lower       = true
      + min_lower   = 0
      + min_numeric = 0
      + min_special = 0
      + min_upper   = 0
      + number      = true
      + numeric     = true
      + result      = (known after apply)
      + special     = false
      + upper       = false
    }

  # module.tfcloud.random_string.rand8 will be created
  + resource "random_string" "rand8" {
      + id          = (known after apply)
      + length      = 8
      + lower       = true
      + min_lower   = 0
      + min_numeric = 0
      + min_special = 0
      + min_upper   = 0
      + number      = true
      + numeric     = true
      + result      = (known after apply)
      + special     = false
      + upper       = false
    }

  # module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID will be created
  + resource "tfe_variable" "AWS_ACCESS_KEY_ID" {
      + category       = "env"
      + description    = "AWS_ACCESS_KEY_ID"
      + hcl            = false
      + id             = (known after apply)
      + key            = "AWS_ACCESS_KEY_ID"
      + readable_value = "AKIAWYELJ4WJTLRM4Z4W"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY will be created
  + resource "tfe_variable" "AWS_SECRET_ACCESS_KEY" {
      + category     = "env"
      + description  = "AWS_SECRET_ACCESS_KEY"
      + hcl          = false
      + id           = (known after apply)
      + key          = "AWS_SECRET_ACCESS_KEY"
      + sensitive    = true
      + value        = (sensitive value)
      + workspace_id = (known after apply)
    }

  # module.tfcloud.tfe_variable.region will be created
  + resource "tfe_variable" "region" {
      + category       = "terraform"
      + description    = "AWS Region"
      + hcl            = false
      + id             = (known after apply)
      + key            = "region"
      + readable_value = "eu-west-1"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_workspace.tf-ws will be created
  + resource "tfe_workspace" "tf-ws" {
      + agent_pool_id                 = (known after apply)
      + allow_destroy_plan            = true
      + auto_apply                    = false
      + auto_apply_run_trigger        = false
      + execution_mode                = (known after apply)
      + file_triggers_enabled         = true
      + force_delete                  = false
      + global_remote_state           = (known after apply)
      + html_url                      = (known after apply)
      + id                            = (known after apply)
      + name                          = (known after apply)
      + operations                    = (known after apply)
      + organization                  = "org"
      + project_id                    = (known after apply)
      + queue_all_runs                = true
      + remote_state_consumer_ids     = (known after apply)
      + resource_count                = (known after apply)
      + speculative_enabled           = true
      + structured_run_output_enabled = true
      + tag_names                     = (known after apply)
      + terraform_version             = (known after apply)
      + working_directory             = "/deploy"
    }

Plan: 9 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + user_instructions = (known after apply)

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.tfcloud.random_string.rand6: Creating...
module.tfcloud.random_string.rand8: Creating...
module.tfcloud.random_string.rand8: Creation complete after 0s [id=9m8qb96a]
module.tfcloud.random_string.rand6: Creation complete after 0s [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Creating...
╷
│ Error: Error creating workspace w-aws-ia-mtpmlv for organization org: resource not found
│ 
│   with module.tfcloud.tfe_workspace.tf-ws,
│   on .terraform/modules/tfcloud/main.tf line 40, in resource "tfe_workspace" "tf-ws":
│   40: resource "tfe_workspace" "tf-ws" {
│ 
╵
markusburg@computer setup_workspace % terraform init                                         
Initializing modules...

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/null v3.2.2
- Using previously-installed hashicorp/tfe v0.51.1

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: Magento

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # null_resource.remoteinit will be created
  + resource "null_resource" "remoteinit" {
      + id = (known after apply)
    }

  # null_resource.setup_backend_file will be created
  + resource "null_resource" "setup_backend_file" {
      + id = (known after apply)
    }

  # module.tfcloud.local_file.backend_file will be created
  + resource "local_file" "backend_file" {
      + content              = <<-EOT
            workspaces { name = "w-aws-ia-mtpmlv" }
            hostname = "app.terraform.io"
            organization = "Magento"
        EOT
      + content_base64sha256 = (known after apply)
      + content_base64sha512 = (known after apply)
      + content_md5          = (known after apply)
      + content_sha1         = (known after apply)
      + content_sha256       = (known after apply)
      + content_sha512       = (known after apply)
      + directory_permission = "0777"
      + file_permission      = "0777"
      + filename             = "backend.hcl"
      + id                   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID will be created
  + resource "tfe_variable" "AWS_ACCESS_KEY_ID" {
      + category       = "env"
      + description    = "AWS_ACCESS_KEY_ID"
      + hcl            = false
      + id             = (known after apply)
      + key            = "AWS_ACCESS_KEY_ID"
      + readable_value = "AKIAWYELJ4WJTLRM4Z4W"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY will be created
  + resource "tfe_variable" "AWS_SECRET_ACCESS_KEY" {
      + category     = "env"
      + description  = "AWS_SECRET_ACCESS_KEY"
      + hcl          = false
      + id           = (known after apply)
      + key          = "AWS_SECRET_ACCESS_KEY"
      + sensitive    = true
      + value        = (sensitive value)
      + workspace_id = (known after apply)
    }

  # module.tfcloud.tfe_variable.region will be created
  + resource "tfe_variable" "region" {
      + category       = "terraform"
      + description    = "AWS Region"
      + hcl            = false
      + id             = (known after apply)
      + key            = "region"
      + readable_value = "eu-west-1"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_workspace.tf-ws will be created
  + resource "tfe_workspace" "tf-ws" {
      + agent_pool_id                 = (known after apply)
      + allow_destroy_plan            = true
      + auto_apply                    = false
      + auto_apply_run_trigger        = false
      + execution_mode                = (known after apply)
      + file_triggers_enabled         = true
      + force_delete                  = false
      + global_remote_state           = (known after apply)
      + html_url                      = (known after apply)
      + id                            = (known after apply)
      + name                          = "w-aws-ia-mtpmlv"
      + operations                    = (known after apply)
      + organization                  = "Magento"
      + project_id                    = (known after apply)
      + queue_all_runs                = true
      + remote_state_consumer_ids     = (known after apply)
      + resource_count                = (known after apply)
      + speculative_enabled           = true
      + structured_run_output_enabled = true
      + tag_names                     = (known after apply)
      + terraform_version             = (known after apply)
      + working_directory             = "/deploy"
    }

Plan: 7 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + user_instructions = <<-EOT
        # org name    = Magento
        # workspace   = w-aws-ia-mtpmlv
        
        
        # Run these commands in order:
        cd ../deploy
        
        # Configure your tfvars file
          AWS_SECRET_ACCESS_KEY = "*****************"
          AWS_ACCESS_KEY_ID     = "*****************"
          AWS_SESSION_TOKEN     = "*****************"
          region                = eu-west-1
        
        #  Note: Use of STS Creds are highly reccommended!
        # !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
        # (and follow secrets mangement bestpractices)
        #   
           terraform apply  -var-file="$HOME/.aws/terraform.tfvars"
    EOT

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.tfcloud.tfe_workspace.tf-ws: Creating...
╷
│ Error: Error creating workspace w-aws-ia-mtpmlv for organization Magento: resource not found
│ 
│   with module.tfcloud.tfe_workspace.tf-ws,
│   on .terraform/modules/tfcloud/main.tf line 40, in resource "tfe_workspace" "tf-ws":
│   40: resource "tfe_workspace" "tf-ws" {
│ 
╵
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: w-aws-ia-mtpmlv

module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # null_resource.remoteinit will be created
  + resource "null_resource" "remoteinit" {
      + id = (known after apply)
    }

  # null_resource.setup_backend_file will be created
  + resource "null_resource" "setup_backend_file" {
      + id = (known after apply)
    }

  # module.tfcloud.local_file.backend_file will be created
  + resource "local_file" "backend_file" {
      + content              = <<-EOT
            workspaces { name = "w-aws-ia-mtpmlv" }
            hostname = "app.terraform.io"
            organization = "w-aws-ia-mtpmlv"
        EOT
      + content_base64sha256 = (known after apply)
      + content_base64sha512 = (known after apply)
      + content_md5          = (known after apply)
      + content_sha1         = (known after apply)
      + content_sha256       = (known after apply)
      + content_sha512       = (known after apply)
      + directory_permission = "0777"
      + file_permission      = "0777"
      + filename             = "backend.hcl"
      + id                   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID will be created
  + resource "tfe_variable" "AWS_ACCESS_KEY_ID" {
      + category       = "env"
      + description    = "AWS_ACCESS_KEY_ID"
      + hcl            = false
      + id             = (known after apply)
      + key            = "AWS_ACCESS_KEY_ID"
      + readable_value = "AKIAWYELJ4WJTLRM4Z4W"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY will be created
  + resource "tfe_variable" "AWS_SECRET_ACCESS_KEY" {
      + category     = "env"
      + description  = "AWS_SECRET_ACCESS_KEY"
      + hcl          = false
      + id           = (known after apply)
      + key          = "AWS_SECRET_ACCESS_KEY"
      + sensitive    = true
      + value        = (sensitive value)
      + workspace_id = (known after apply)
    }

  # module.tfcloud.tfe_variable.region will be created
  + resource "tfe_variable" "region" {
      + category       = "terraform"
      + description    = "AWS Region"
      + hcl            = false
      + id             = (known after apply)
      + key            = "region"
      + readable_value = "eu-west-1"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_workspace.tf-ws will be created
  + resource "tfe_workspace" "tf-ws" {
      + agent_pool_id                 = (known after apply)
      + allow_destroy_plan            = true
      + auto_apply                    = false
      + auto_apply_run_trigger        = false
      + execution_mode                = (known after apply)
      + file_triggers_enabled         = true
      + force_delete                  = false
      + global_remote_state           = (known after apply)
      + html_url                      = (known after apply)
      + id                            = (known after apply)
      + name                          = "w-aws-ia-mtpmlv"
      + operations                    = (known after apply)
      + organization                  = "w-aws-ia-mtpmlv"
      + project_id                    = (known after apply)
      + queue_all_runs                = true
      + remote_state_consumer_ids     = (known after apply)
      + resource_count                = (known after apply)
      + speculative_enabled           = true
      + structured_run_output_enabled = true
      + tag_names                     = (known after apply)
      + terraform_version             = (known after apply)
      + working_directory             = "/deploy"
    }

Plan: 7 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  ~ user_instructions = <<-EOT
      - # org name    = Magento
      + # org name    = w-aws-ia-mtpmlv
        # workspace   = w-aws-ia-mtpmlv
        
        
        # Run these commands in order:
        cd ../deploy
        
        # Configure your tfvars file
          AWS_SECRET_ACCESS_KEY = "*****************"
          AWS_ACCESS_KEY_ID     = "*****************"
          AWS_SESSION_TOKEN     = "*****************"
          region                = eu-west-1
        
        #  Note: Use of STS Creds are highly reccommended!
        # !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
        # (and follow secrets mangement bestpractices)
        #   
           terraform apply  -var-file="$HOME/.aws/terraform.tfvars"
    EOT

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.tfcloud.tfe_workspace.tf-ws: Creating...
╷
│ Error: Error creating workspace w-aws-ia-mtpmlv for organization w-aws-ia-mtpmlv: resource not found
│ 
│   with module.tfcloud.tfe_workspace.tf-ws,
│   on .terraform/modules/tfcloud/main.tf line 40, in resource "tfe_workspace" "tf-ws":
│   40: resource "tfe_workspace" "tf-ws" {
│ 
╵
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # null_resource.remoteinit will be created
  + resource "null_resource" "remoteinit" {
      + id = (known after apply)
    }

  # null_resource.setup_backend_file will be created
  + resource "null_resource" "setup_backend_file" {
      + id = (known after apply)
    }

  # module.tfcloud.local_file.backend_file will be created
  + resource "local_file" "backend_file" {
      + content              = <<-EOT
            workspaces { name = "w-aws-ia-mtpmlv" }
            hostname = "app.terraform.io"
            organization = "tudublin"
        EOT
      + content_base64sha256 = (known after apply)
      + content_base64sha512 = (known after apply)
      + content_md5          = (known after apply)
      + content_sha1         = (known after apply)
      + content_sha256       = (known after apply)
      + content_sha512       = (known after apply)
      + directory_permission = "0777"
      + file_permission      = "0777"
      + filename             = "backend.hcl"
      + id                   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID will be created
  + resource "tfe_variable" "AWS_ACCESS_KEY_ID" {
      + category       = "env"
      + description    = "AWS_ACCESS_KEY_ID"
      + hcl            = false
      + id             = (known after apply)
      + key            = "AWS_ACCESS_KEY_ID"
      + readable_value = "AKIAWYELJ4WJTLRM4Z4W"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY will be created
  + resource "tfe_variable" "AWS_SECRET_ACCESS_KEY" {
      + category     = "env"
      + description  = "AWS_SECRET_ACCESS_KEY"
      + hcl          = false
      + id           = (known after apply)
      + key          = "AWS_SECRET_ACCESS_KEY"
      + sensitive    = true
      + value        = (sensitive value)
      + workspace_id = (known after apply)
    }

  # module.tfcloud.tfe_variable.region will be created
  + resource "tfe_variable" "region" {
      + category       = "terraform"
      + description    = "AWS Region"
      + hcl            = false
      + id             = (known after apply)
      + key            = "region"
      + readable_value = "eu-west-1"
      + sensitive      = false
      + value          = (sensitive value)
      + workspace_id   = (known after apply)
    }

  # module.tfcloud.tfe_workspace.tf-ws will be created
  + resource "tfe_workspace" "tf-ws" {
      + agent_pool_id                 = (known after apply)
      + allow_destroy_plan            = true
      + auto_apply                    = false
      + auto_apply_run_trigger        = false
      + execution_mode                = (known after apply)
      + file_triggers_enabled         = true
      + force_delete                  = false
      + global_remote_state           = (known after apply)
      + html_url                      = (known after apply)
      + id                            = (known after apply)
      + name                          = "w-aws-ia-mtpmlv"
      + operations                    = (known after apply)
      + organization                  = "tudublin"
      + project_id                    = (known after apply)
      + queue_all_runs                = true
      + remote_state_consumer_ids     = (known after apply)
      + resource_count                = (known after apply)
      + speculative_enabled           = true
      + structured_run_output_enabled = true
      + tag_names                     = (known after apply)
      + terraform_version             = (known after apply)
      + working_directory             = "/deploy"
    }

Plan: 7 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  ~ user_instructions = <<-EOT
      - # org name    = w-aws-ia-mtpmlv
      + # org name    = tudublin
        # workspace   = w-aws-ia-mtpmlv
        
        
        # Run these commands in order:
        cd ../deploy
        
        # Configure your tfvars file
          AWS_SECRET_ACCESS_KEY = "*****************"
          AWS_ACCESS_KEY_ID     = "*****************"
          AWS_SESSION_TOKEN     = "*****************"
          region                = eu-west-1
        
        #  Note: Use of STS Creds are highly reccommended!
        # !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
        # (and follow secrets mangement bestpractices)
        #   
           terraform apply  -var-file="$HOME/.aws/terraform.tfvars"
    EOT

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.tfcloud.tfe_workspace.tf-ws: Creating...
module.tfcloud.tfe_workspace.tf-ws: Creation complete after 1s [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Creating...
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Creating...
module.tfcloud.tfe_variable.region: Creating...
module.tfcloud.local_file.backend_file: Creating...
module.tfcloud.local_file.backend_file: Creation complete after 0s [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Creation complete after 0s [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.region: Creation complete after 0s [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Creation complete after 0s [id=var-oWCRSq1hnBRhDQ9B]
null_resource.setup_backend_file: Creating...
null_resource.setup_backend_file: Provisioning with 'local-exec'...
null_resource.setup_backend_file (local-exec): Executing: ["/bin/sh" "-c" "mv backend.hcl ../deploy"]
null_resource.setup_backend_file: Creation complete after 0s [id=5430304601694551473]
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]
null_resource.remoteinit (local-exec): Initializing modules...
null_resource.remoteinit (local-exec): There are some problems with the configuration, described below.

null_resource.remoteinit (local-exec): The Terraform configuration must be valid before initialization so that
null_resource.remoteinit (local-exec): Terraform can determine which modules and providers need to be installed.
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Invalid default value for variable
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables 2.tf line 92, in variable "management_addresses":
null_resource.remoteinit (local-exec): │   92:   default     = "10.0.0.0/32"
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ This default value is not compatible with the variable's type constraint:
null_resource.remoteinit (local-exec): │ list of string required.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 5:
null_resource.remoteinit (local-exec): │    5: variable "project" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "project" was already declared at variables 2.tf:5,1-19.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 11:
null_resource.remoteinit (local-exec): │   11: variable "domain_name" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "domain_name" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:11,1-23. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 21:
null_resource.remoteinit (local-exec): │   21: variable "profile" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "profile" was already declared at variables 2.tf:21,1-19.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 30:
null_resource.remoteinit (local-exec): │   30: variable "ssh_key_name" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "ssh_key_name" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:30,1-24. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 36:
null_resource.remoteinit (local-exec): │   36: variable "ssh_key_pair_name" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "ssh_key_pair_name" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:36,1-29. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 42:
null_resource.remoteinit (local-exec): │   42: variable "ssh_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "ssh_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:42,1-24. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 48:
null_resource.remoteinit (local-exec): │   48: variable "base_ami_os" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "base_ami_os" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:48,1-23. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 56:
null_resource.remoteinit (local-exec): │   56: variable "region" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "region" was already declared at variables 2.tf:56,1-18.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 62:
null_resource.remoteinit (local-exec): │   62: variable "az1" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "az1" was already declared at variables 2.tf:62,1-15.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 68:
null_resource.remoteinit (local-exec): │   68: variable "az2" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "az2" was already declared at variables 2.tf:68,1-15.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 77:
null_resource.remoteinit (local-exec): │   77: variable "create_vpc" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "create_vpc" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:77,1-22. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 83:
null_resource.remoteinit (local-exec): │   83: variable "vpc_cidr" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_cidr" was already declared at variables 2.tf:83,1-20.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 89:
null_resource.remoteinit (local-exec): │   89: variable "management_addresses" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "management_addresses" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:89,1-32. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 98:
null_resource.remoteinit (local-exec): │   98: variable "mage_composer_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "mage_composer_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:98,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 104:
null_resource.remoteinit (local-exec): │  104: variable "mage_composer_password" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "mage_composer_password" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:104,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 110:
null_resource.remoteinit (local-exec): │  110: variable "magento_admin_firstname" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_firstname" was already declared at
null_resource.remoteinit (local-exec): │ variables 2.tf:110,1-35. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 116:
null_resource.remoteinit (local-exec): │  116: variable "magento_admin_lastname" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_lastname" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:116,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 122:
null_resource.remoteinit (local-exec): │  122: variable "magento_admin_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:122,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 128:
null_resource.remoteinit (local-exec): │  128: variable "magento_admin_password" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_password" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:128,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 134:
null_resource.remoteinit (local-exec): │  134: variable "magento_admin_email" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_email" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:134,1-31. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 143:
null_resource.remoteinit (local-exec): │  143: variable "magento_database_password" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_database_password" was already declared at
null_resource.remoteinit (local-exec): │ variables 2.tf:143,1-37. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 152:
null_resource.remoteinit (local-exec): │  152: variable "elasticsearch_domain" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "elasticsearch_domain" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:152,1-32. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 161:
null_resource.remoteinit (local-exec): │  161: variable "rabbitmq_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "rabbitmq_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:161,1-29. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 172:
null_resource.remoteinit (local-exec): │  172: variable "vpc_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_id" was already declared at variables 2.tf:172,1-18.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 177:
null_resource.remoteinit (local-exec): │  177: variable "vpc_public_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_public_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:177,1-32. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 183:
null_resource.remoteinit (local-exec): │  183: variable "vpc_public2_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_public2_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:183,1-33. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 189:
null_resource.remoteinit (local-exec): │  189: variable "vpc_private_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_private_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:189,1-33. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 195:
null_resource.remoteinit (local-exec): │  195: variable "vpc_private2_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_private2_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:195,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 201:
null_resource.remoteinit (local-exec): │  201: variable "vpc_rds_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_rds_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:201,1-29. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 207:
null_resource.remoteinit (local-exec): │  207: variable "vpc_rds_subnet2_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_rds_subnet2_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:207,1-30. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 218:
null_resource.remoteinit (local-exec): │  218: variable "cert" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "cert" was already declared at variables 2.tf:218,1-16.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output:  2.tf:89,1-32. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 98:
│ │   98: variable "mage_composer_username" {
│ │ 
│ │ A variable named "mage_composer_username" was already declared at variables
│ │ 2.tf:98,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 104:
│ │  104: variable "mage_composer_password" {
│ │ 
│ │ A variable named "mage_composer_password" was already declared at variables
│ │ 2.tf:104,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 110:
│ │  110: variable "magento_admin_firstname" {
│ │ 
│ │ A variable named "magento_admin_firstname" was already declared at
│ │ variables 2.tf:110,1-35. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 116:
│ │  116: variable "magento_admin_lastname" {
│ │ 
│ │ A variable named "magento_admin_lastname" was already declared at variables
│ │ 2.tf:116,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 122:
│ │  122: variable "magento_admin_username" {
│ │ 
│ │ A variable named "magento_admin_username" was already declared at variables
│ │ 2.tf:122,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 128:
│ │  128: variable "magento_admin_password" {
│ │ 
│ │ A variable named "magento_admin_password" was already declared at variables
│ │ 2.tf:128,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 134:
│ │  134: variable "magento_admin_email" {
│ │ 
│ │ A variable named "magento_admin_email" was already declared at variables
│ │ 2.tf:134,1-31. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 143:
│ │  143: variable "magento_database_password" {
│ │ 
│ │ A variable named "magento_database_password" was already declared at
│ │ variables 2.tf:143,1-37. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 152:
│ │  152: variable "elasticsearch_domain" {
│ │ 
│ │ A variable named "elasticsearch_domain" was already declared at variables
│ │ 2.tf:152,1-32. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 161:
│ │  161: variable "rabbitmq_username" {
│ │ 
│ │ A variable named "rabbitmq_username" was already declared at variables
│ │ 2.tf:161,1-29. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 172:
│ │  172: variable "vpc_id" {
│ │ 
│ │ A variable named "vpc_id" was already declared at variables 2.tf:172,1-18.
│ │ Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 177:
│ │  177: variable "vpc_public_subnet_id" {
│ │ 
│ │ A variable named "vpc_public_subnet_id" was already declared at variables
│ │ 2.tf:177,1-32. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 183:
│ │  183: variable "vpc_public2_subnet_id" {
│ │ 
│ │ A variable named "vpc_public2_subnet_id" was already declared at variables
│ │ 2.tf:183,1-33. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 189:
│ │  189: variable "vpc_private_subnet_id" {
│ │ 
│ │ A variable named "vpc_private_subnet_id" was already declared at variables
│ │ 2.tf:189,1-33. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 195:
│ │  195: variable "vpc_private2_subnet_id" {
│ │ 
│ │ A variable named "vpc_private2_subnet_id" was already declared at variables
│ │ 2.tf:195,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 201:
│ │  201: variable "vpc_rds_subnet_id" {
│ │ 
│ │ A variable named "vpc_rds_subnet_id" was already declared at variables
│ │ 2.tf:201,1-29. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 207:
│ │  207: variable "vpc_rds_subnet2_id" {
│ │ 
│ │ A variable named "vpc_rds_subnet2_id" was already declared at variables
│ │ 2.tf:207,1-30. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 218:
│ │  218: variable "cert" {
│ │ 
│ │ A variable named "cert" was already declared at variables 2.tf:218,1-16.
│ │ Variable names must be unique within a module.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % terraform init                                                         
Initializing modules...

Initializing the backend...

Initializing provider plugins...
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/null v3.2.2
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/random v3.6.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=1812620157478762514]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "1812620157478762514" -> (known after apply)
    }

  # module.tfcloud.local_file.backend_file will be created
  + resource "local_file" "backend_file" {
      + content              = <<-EOT
            workspaces { name = "w-aws-ia-mtpmlv" }
            hostname = "app.terraform.io"
            organization = "tudublin"
        EOT
      + content_base64sha256 = (known after apply)
      + content_base64sha512 = (known after apply)
      + content_md5          = (known after apply)
      + content_sha1         = (known after apply)
      + content_sha256       = (known after apply)
      + content_sha512       = (known after apply)
      + directory_permission = "0777"
      + file_permission      = "0777"
      + filename             = "backend.hcl"
      + id                   = (known after apply)
    }

Plan: 2 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=1812620157478762514]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]
null_resource.remoteinit (local-exec): Initializing modules...
null_resource.remoteinit (local-exec): There are some problems with the configuration, described below.

null_resource.remoteinit (local-exec): The Terraform configuration must be valid before initialization so that
null_resource.remoteinit (local-exec): Terraform can determine which modules and providers need to be installed.
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Invalid default value for variable
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables 2.tf line 92, in variable "management_addresses":
null_resource.remoteinit (local-exec): │   92:   default     = "10.0.0.0/32"
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ This default value is not compatible with the variable's type constraint:
null_resource.remoteinit (local-exec): │ list of string required.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 5:
null_resource.remoteinit (local-exec): │    5: variable "project" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "project" was already declared at variables 2.tf:5,1-19.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 11:
null_resource.remoteinit (local-exec): │   11: variable "domain_name" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "domain_name" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:11,1-23. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 21:
null_resource.remoteinit (local-exec): │   21: variable "profile" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "profile" was already declared at variables 2.tf:21,1-19.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 30:
null_resource.remoteinit (local-exec): │   30: variable "ssh_key_name" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "ssh_key_name" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:30,1-24. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 36:
null_resource.remoteinit (local-exec): │   36: variable "ssh_key_pair_name" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "ssh_key_pair_name" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:36,1-29. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 42:
null_resource.remoteinit (local-exec): │   42: variable "ssh_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "ssh_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:42,1-24. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 48:
null_resource.remoteinit (local-exec): │   48: variable "base_ami_os" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "base_ami_os" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:48,1-23. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 56:
null_resource.remoteinit (local-exec): │   56: variable "region" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "region" was already declared at variables 2.tf:56,1-18.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 62:
null_resource.remoteinit (local-exec): │   62: variable "az1" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "az1" was already declared at variables 2.tf:62,1-15.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 68:
null_resource.remoteinit (local-exec): │   68: variable "az2" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "az2" was already declared at variables 2.tf:68,1-15.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 77:
null_resource.remoteinit (local-exec): │   77: variable "create_vpc" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "create_vpc" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:77,1-22. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 83:
null_resource.remoteinit (local-exec): │   83: variable "vpc_cidr" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_cidr" was already declared at variables 2.tf:83,1-20.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 89:
null_resource.remoteinit (local-exec): │   89: variable "management_addresses" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "management_addresses" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:89,1-32. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 98:
null_resource.remoteinit (local-exec): │   98: variable "mage_composer_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "mage_composer_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:98,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 104:
null_resource.remoteinit (local-exec): │  104: variable "mage_composer_password" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "mage_composer_password" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:104,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 110:
null_resource.remoteinit (local-exec): │  110: variable "magento_admin_firstname" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_firstname" was already declared at
null_resource.remoteinit (local-exec): │ variables 2.tf:110,1-35. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 116:
null_resource.remoteinit (local-exec): │  116: variable "magento_admin_lastname" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_lastname" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:116,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 122:
null_resource.remoteinit (local-exec): │  122: variable "magento_admin_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:122,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 128:
null_resource.remoteinit (local-exec): │  128: variable "magento_admin_password" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_password" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:128,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 134:
null_resource.remoteinit (local-exec): │  134: variable "magento_admin_email" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_admin_email" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:134,1-31. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 143:
null_resource.remoteinit (local-exec): │  143: variable "magento_database_password" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "magento_database_password" was already declared at
null_resource.remoteinit (local-exec): │ variables 2.tf:143,1-37. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 152:
null_resource.remoteinit (local-exec): │  152: variable "elasticsearch_domain" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "elasticsearch_domain" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:152,1-32. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 161:
null_resource.remoteinit (local-exec): │  161: variable "rabbitmq_username" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "rabbitmq_username" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:161,1-29. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 172:
null_resource.remoteinit (local-exec): │  172: variable "vpc_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_id" was already declared at variables 2.tf:172,1-18.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 177:
null_resource.remoteinit (local-exec): │  177: variable "vpc_public_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_public_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:177,1-32. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 183:
null_resource.remoteinit (local-exec): │  183: variable "vpc_public2_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_public2_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:183,1-33. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 189:
null_resource.remoteinit (local-exec): │  189: variable "vpc_private_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_private_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:189,1-33. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 195:
null_resource.remoteinit (local-exec): │  195: variable "vpc_private2_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_private2_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:195,1-34. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 201:
null_resource.remoteinit (local-exec): │  201: variable "vpc_rds_subnet_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_rds_subnet_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:201,1-29. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 207:
null_resource.remoteinit (local-exec): │  207: variable "vpc_rds_subnet2_id" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "vpc_rds_subnet2_id" was already declared at variables
null_resource.remoteinit (local-exec): │ 2.tf:207,1-30. Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Duplicate variable declaration
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │   on variables.tf line 218:
null_resource.remoteinit (local-exec): │  218: variable "cert" {
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ A variable named "cert" was already declared at variables 2.tf:218,1-16.
null_resource.remoteinit (local-exec): │ Variable names must be unique within a module.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
module.tfcloud.local_file.backend_file: Creating...
module.tfcloud.local_file.backend_file: Creation complete after 0s [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output:  2.tf:89,1-32. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 98:
│ │   98: variable "mage_composer_username" {
│ │ 
│ │ A variable named "mage_composer_username" was already declared at variables
│ │ 2.tf:98,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 104:
│ │  104: variable "mage_composer_password" {
│ │ 
│ │ A variable named "mage_composer_password" was already declared at variables
│ │ 2.tf:104,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 110:
│ │  110: variable "magento_admin_firstname" {
│ │ 
│ │ A variable named "magento_admin_firstname" was already declared at
│ │ variables 2.tf:110,1-35. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 116:
│ │  116: variable "magento_admin_lastname" {
│ │ 
│ │ A variable named "magento_admin_lastname" was already declared at variables
│ │ 2.tf:116,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 122:
│ │  122: variable "magento_admin_username" {
│ │ 
│ │ A variable named "magento_admin_username" was already declared at variables
│ │ 2.tf:122,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 128:
│ │  128: variable "magento_admin_password" {
│ │ 
│ │ A variable named "magento_admin_password" was already declared at variables
│ │ 2.tf:128,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 134:
│ │  134: variable "magento_admin_email" {
│ │ 
│ │ A variable named "magento_admin_email" was already declared at variables
│ │ 2.tf:134,1-31. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 143:
│ │  143: variable "magento_database_password" {
│ │ 
│ │ A variable named "magento_database_password" was already declared at
│ │ variables 2.tf:143,1-37. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 152:
│ │  152: variable "elasticsearch_domain" {
│ │ 
│ │ A variable named "elasticsearch_domain" was already declared at variables
│ │ 2.tf:152,1-32. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 161:
│ │  161: variable "rabbitmq_username" {
│ │ 
│ │ A variable named "rabbitmq_username" was already declared at variables
│ │ 2.tf:161,1-29. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 172:
│ │  172: variable "vpc_id" {
│ │ 
│ │ A variable named "vpc_id" was already declared at variables 2.tf:172,1-18.
│ │ Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 177:
│ │  177: variable "vpc_public_subnet_id" {
│ │ 
│ │ A variable named "vpc_public_subnet_id" was already declared at variables
│ │ 2.tf:177,1-32. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 183:
│ │  183: variable "vpc_public2_subnet_id" {
│ │ 
│ │ A variable named "vpc_public2_subnet_id" was already declared at variables
│ │ 2.tf:183,1-33. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 189:
│ │  189: variable "vpc_private_subnet_id" {
│ │ 
│ │ A variable named "vpc_private_subnet_id" was already declared at variables
│ │ 2.tf:189,1-33. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 195:
│ │  195: variable "vpc_private2_subnet_id" {
│ │ 
│ │ A variable named "vpc_private2_subnet_id" was already declared at variables
│ │ 2.tf:195,1-34. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 201:
│ │  201: variable "vpc_rds_subnet_id" {
│ │ 
│ │ A variable named "vpc_rds_subnet_id" was already declared at variables
│ │ 2.tf:201,1-29. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 207:
│ │  207: variable "vpc_rds_subnet2_id" {
│ │ 
│ │ A variable named "vpc_rds_subnet2_id" was already declared at variables
│ │ 2.tf:207,1-30. Variable names must be unique within a module.
│ ╵
│ 
│ ╷
│ │ Error: Duplicate variable declaration
│ │ 
│ │   on variables.tf line 218:
│ │  218: variable "cert" {
│ │ 
│ │ A variable named "cert" was already declared at variables 2.tf:218,1-16.
│ │ Variable names must be unique within a module.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % cd ../deploy
markusburg@computer deploy % nano ./deploy/variables.tf
markusburg@computer deploy % nano variables.tf 
markusburg@computer deploy % terraform init                                         
Initializing modules...
There are some problems with the configuration, described below.

The Terraform configuration must be valid before initialization so that
Terraform can determine which modules and providers need to be installed.
╷
│ Error: Invalid default value for variable
│ 
│   on variables 2.tf line 92, in variable "management_addresses":
│   92:   default     = "10.0.0.0/32"
│ 
│ This default value is not compatible with the variable's type constraint: list of string required.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 5:
│    5: variable "project" {
│ 
│ A variable named "project" was already declared at variables 2.tf:5,1-19. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 11:
│   11: variable "domain_name" {
│ 
│ A variable named "domain_name" was already declared at variables 2.tf:11,1-23. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 21:
│   21: variable "profile" {
│ 
│ A variable named "profile" was already declared at variables 2.tf:21,1-19. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 30:
│   30: variable "ssh_key_name" {
│ 
│ A variable named "ssh_key_name" was already declared at variables 2.tf:30,1-24. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 36:
│   36: variable "ssh_key_pair_name" {
│ 
│ A variable named "ssh_key_pair_name" was already declared at variables 2.tf:36,1-29. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 42:
│   42: variable "ssh_username" {
│ 
│ A variable named "ssh_username" was already declared at variables 2.tf:42,1-24. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 48:
│   48: variable "base_ami_os" {
│ 
│ A variable named "base_ami_os" was already declared at variables 2.tf:48,1-23. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 56:
│   56: variable "region" {
│ 
│ A variable named "region" was already declared at variables 2.tf:56,1-18. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 62:
│   62: variable "az1" {
│ 
│ A variable named "az1" was already declared at variables 2.tf:62,1-15. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 68:
│   68: variable "az2" {
│ 
│ A variable named "az2" was already declared at variables 2.tf:68,1-15. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 77:
│   77: variable "create_vpc" {
│ 
│ A variable named "create_vpc" was already declared at variables 2.tf:77,1-22. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 83:
│   83: variable "vpc_cidr" {
│ 
│ A variable named "vpc_cidr" was already declared at variables 2.tf:83,1-20. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 89:
│   89: variable "management_addresses" {
│ 
│ A variable named "management_addresses" was already declared at variables 2.tf:89,1-32. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 98:
│   98: variable "mage_composer_username" {
│ 
│ A variable named "mage_composer_username" was already declared at variables 2.tf:98,1-34. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 104:
│  104: variable "mage_composer_password" {
│ 
│ A variable named "mage_composer_password" was already declared at variables 2.tf:104,1-34. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 110:
│  110: variable "magento_admin_firstname" {
│ 
│ A variable named "magento_admin_firstname" was already declared at variables 2.tf:110,1-35. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 116:
│  116: variable "magento_admin_lastname" {
│ 
│ A variable named "magento_admin_lastname" was already declared at variables 2.tf:116,1-34. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 122:
│  122: variable "magento_admin_username" {
│ 
│ A variable named "magento_admin_username" was already declared at variables 2.tf:122,1-34. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 128:
│  128: variable "magento_admin_password" {
│ 
│ A variable named "magento_admin_password" was already declared at variables 2.tf:128,1-34. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 134:
│  134: variable "magento_admin_email" {
│ 
│ A variable named "magento_admin_email" was already declared at variables 2.tf:134,1-31. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 143:
│  143: variable "magento_database_password" {
│ 
│ A variable named "magento_database_password" was already declared at variables 2.tf:143,1-37. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 152:
│  152: variable "elasticsearch_domain" {
│ 
│ A variable named "elasticsearch_domain" was already declared at variables 2.tf:152,1-32. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 161:
│  161: variable "rabbitmq_username" {
│ 
│ A variable named "rabbitmq_username" was already declared at variables 2.tf:161,1-29. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 172:
│  172: variable "vpc_id" {
│ 
│ A variable named "vpc_id" was already declared at variables 2.tf:172,1-18. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 177:
│  177: variable "vpc_public_subnet_id" {
│ 
│ A variable named "vpc_public_subnet_id" was already declared at variables 2.tf:177,1-32. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 183:
│  183: variable "vpc_public2_subnet_id" {
│ 
│ A variable named "vpc_public2_subnet_id" was already declared at variables 2.tf:183,1-33. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 189:
│  189: variable "vpc_private_subnet_id" {
│ 
│ A variable named "vpc_private_subnet_id" was already declared at variables 2.tf:189,1-33. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 195:
│  195: variable "vpc_private2_subnet_id" {
│ 
│ A variable named "vpc_private2_subnet_id" was already declared at variables 2.tf:195,1-34. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 201:
│  201: variable "vpc_rds_subnet_id" {
│ 
│ A variable named "vpc_rds_subnet_id" was already declared at variables 2.tf:201,1-29. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 207:
│  207: variable "vpc_rds_subnet2_id" {
│ 
│ A variable named "vpc_rds_subnet2_id" was already declared at variables 2.tf:207,1-30. Variable names must be unique within a module.
╵

╷
│ Error: Duplicate variable declaration
│ 
│   on variables.tf line 218:
│  218: variable "cert" {
│ 
│ A variable named "cert" was already declared at variables 2.tf:218,1-16. Variable names must be unique within a module.
╵

markusburg@computer deploy % terraform init
Initializing modules...
There are some problems with the configuration, described below.

The Terraform configuration must be valid before initialization so that
Terraform can determine which modules and providers need to be installed.
╷
│ Error: Module is incompatible with count, for_each, and depends_on
│ 
│   on ../main.tf line 122, in module "magento-ami":
│  122:     module.services
│ 
│ The module at module.magento is a legacy module which contains its own local provider configurations, and so calls to it may not use the count, for_each, or
│ depends_on arguments.
│ 
│ If you also control the module "./..", consider updating this module to instead expect provider configurations to be passed by its caller.
╵

markusburg@computer deploy % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
╷
│ Error: Backend initialization required, please run "terraform init"
│ 
│ Reason: Initial configuration of the requested backend "remote"
│ 
│ The "backend" is the interface that Terraform uses to store state,
│ perform operations, etc. If this message is showing up, it means that the
│ Terraform configuration you're using is using a custom configuration for
│ the Terraform backend.
│ 
│ Changes to backend configurations require reinitialization. This allows
│ Terraform to set up the new configuration, copy existing state, etc. Please run
│ "terraform init" with either the "-reconfigure" or "-migrate-state" flags to
│ use the current configuration.
│ 
│ If the change reason above is incorrect, please verify your configuration
│ hasn't changed and try again. At this point, no changes to your existing
│ configuration or state have been made.
╵
markusburg@computer deploy % terraform init                                         
Initializing modules...
There are some problems with the configuration, described below.

The Terraform configuration must be valid before initialization so that
Terraform can determine which modules and providers need to be installed.
╷
│ Error: Module is incompatible with count, for_each, and depends_on
│ 
│   on ../main.tf line 103, in module "services":
│  103:     module.base
│ 
│ The module at module.magento is a legacy module which contains its own local provider configurations, and so calls to it may not use the count, for_each, or
│ depends_on arguments.
│ 
│ If you also control the module "./..", consider updating this module to instead expect provider configurations to be passed by its caller.
╵

markusburg@computer deploy % terraform -v                                           
Terraform v1.2.0
on darwin_arm64

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer deploy % tfswitch 
Reading required version from terraform file
Reading required version from constraint: >= 1.0.5
Matched version: 1.7.0
Installing terraform at /Users/markusburg/bin
Downloading to: /Users/markusburg/.terraform.versions
25891366 bytes downloaded
Switched terraform to version "1.7.0" 
markusburg@computer deploy % terraform -v
Terraform v1.7.0
on darwin_arm64
markusburg@computer deploy % terraform init

Initializing the backend...
organization
  The name of the organization containing the targeted workspace(s).

  Enter a value: tudublin

Initializing modules...
╷
│ Error: Invalid workspaces configuration
│ 
│   on versions.tf line 3, in terraform:
│    3:   backend "remote" {}
│ 
│ Either workspace "name" or "prefix" is required.
╵

markusburg@computer deploy % tfswitch use 1.7.0
✔ 1.7.0 *recent
Installing terraform at /Users/markusburg/bin
Switched terraform to version "1.7.0" 
markusburg@computer deploy % terraform init    

Initializing the backend...
organization
  The name of the organization containing the targeted workspace(s).

  Enter a value: tudublin

Initializing modules...
╷
│ Error: Invalid workspaces configuration
│ 
│   on versions.tf line 3, in terraform:
│    3:   backend "remote" {}
│ 
│ Either workspace "name" or "prefix" is required.
╵

markusburg@computer deploy % cd ..
markusburg@computer terraform-adobe-magento-main % cd setup_workspace 
markusburg@computer setup_workspace % terraform init    

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/null v3.2.2
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/random v3.6.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eur-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=7565715172932567426]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  ~ update in-place
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "7565715172932567426" -> (known after apply)
    }

  # module.tfcloud.tfe_variable.region will be updated in-place
  ~ resource "tfe_variable" "region" {
        id             = "var-ESaZZgMSBqYjq4Ei"
      ~ readable_value = "eu-west-1" -> "eur-west-1"
      ~ value          = (sensitive value)
        # (6 unchanged attributes hidden)
    }

Plan: 1 to add, 1 to change, 1 to destroy.

Changes to Outputs:
  ~ user_instructions = <<-EOT
        # org name    = tudublin
        # workspace   = w-aws-ia-mtpmlv
        
        
        # Run these commands in order:
        cd ../deploy
        
        # Configure your tfvars file
          AWS_SECRET_ACCESS_KEY = "*****************"
          AWS_ACCESS_KEY_ID     = "*****************"
          AWS_SESSION_TOKEN     = "*****************"
      -   region                = eu-west-1
      +   region                = eur-west-1
        
        #  Note: Use of STS Creds are highly reccommended!
        # !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
        # (and follow secrets mangement bestpractices)
        #   
           terraform apply  -var-file="$HOME/.aws/terraform.tfvars"
    EOT

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=7565715172932567426]
null_resource.remoteinit: Destruction complete after 0s
module.tfcloud.tfe_variable.region: Modifying... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.region: Modifications complete after 0s [id=var-ESaZZgMSBqYjq4Ei]
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): Successfully configured the backend "remote"! Terraform will automatically
null_resource.remoteinit (local-exec): use this backend unless the backend configuration changes.
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/template v2.2.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v2.2.0 (unauthenticated)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_arm64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ 
│ Successfully configured the backend "remote"! Terraform will automatically
│ use this backend unless the backend configuration changes.
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding latest version of hashicorp/template...
│ - Finding latest version of hashicorp/random...
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/template v2.2.0...
│ - Installed hashicorp/template v2.2.0 (unauthenticated)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
│ │ package available for your current platform, darwin_arm64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % tfswitch -l                                            
✔ 1.6.6
Installing terraform at /Users/markusburg/bin
Downloading to: /Users/markusburg/.terraform.versions
24865571 bytes downloaded
Switched terraform to version "1.6.6" 
markusburg@computer setup_workspace % tfswitch use 1.6.6                                     
✔ 1.6.6 *recent
Installing terraform at /Users/markusburg/bin
Switched terraform to version "1.6.6" 
markusburg@computer setup_workspace % terraform init                                         

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/null v3.2.2

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=651336075204701247]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  ~ update in-place
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "651336075204701247" -> (known after apply)
    }

  # module.tfcloud.tfe_variable.region will be updated in-place
  ~ resource "tfe_variable" "region" {
        id             = "var-ESaZZgMSBqYjq4Ei"
      ~ readable_value = "eur-west-1" -> "eu-west-1"
      ~ value          = (sensitive value)
        # (6 unchanged attributes hidden)
    }

Plan: 1 to add, 1 to change, 1 to destroy.

Changes to Outputs:
  ~ user_instructions = <<-EOT
        # org name    = tudublin
        # workspace   = w-aws-ia-mtpmlv
        
        
        # Run these commands in order:
        cd ../deploy
        
        # Configure your tfvars file
          AWS_SECRET_ACCESS_KEY = "*****************"
          AWS_ACCESS_KEY_ID     = "*****************"
          AWS_SESSION_TOKEN     = "*****************"
      -   region                = eur-west-1
      +   region                = eu-west-1
        
        #  Note: Use of STS Creds are highly reccommended!
        # !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
        # (and follow secrets mangement bestpractices)
        #   
           terraform apply  -var-file="$HOME/.aws/terraform.tfvars"
    EOT

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=651336075204701247]
null_resource.remoteinit: Destruction complete after 0s
module.tfcloud.tfe_variable.region: Modifying... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.region: Modifications complete after 0s [id=var-ESaZZgMSBqYjq4Ei]
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/template v2.2.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v2.2.0 (unauthenticated)
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_arm64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding latest version of hashicorp/template...
│ - Finding latest version of hashicorp/random...
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/template v2.2.0...
│ - Installed hashicorp/template v2.2.0 (unauthenticated)
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
│ │ package available for your current platform, darwin_arm64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % brew uninstall tfswitch                                                                                                  
Uninstalling /opt/homebrew/Cellar/tfswitch/0.13.1308... (6 files, 10.1MB)
markusburg@computer setup_workspace % brew uninstall terraform
Uninstalling /opt/homebrew/Cellar/terraform/1.6.6... (3 files, 84.7MB)
markusburg@computer setup_workspace % brew install  m1-terraform-provider-helper 
Running `brew update --auto-update`...
==> Auto-updated Homebrew!
Updated 2 taps (hashicorp/tap and homebrew/cask).

Warning: kreuzwerker/taps/m1-terraform-provider-helper 0.9.0 is already installed and up-to-date.
To reinstall 0.9.0, run:
  brew reinstall m1-terraform-provider-helper
markusburg@computer setup_workspace % brew reinstall m1-terraform-provider-helper
==> Fetching kreuzwerker/taps/m1-terraform-provider-helper
==> Downloading https://github.com/kreuzwerker/m1-terraform-provider-helper/releases/download/0.9.0/m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/0452e3a4a0e2aabeaedbabdd93ddfbb22d29dddd703ecb2e28498beb50897cd9--m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
==> Reinstalling kreuzwerker/taps/m1-terraform-provider-helper 
🍺  /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0: 6 files, 12.8MB, built in 1 second
==> Running `brew cleanup m1-terraform-provider-helper`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer setup_workspace % terraform -v
Terraform v1.6.6
on darwin_arm64
+ provider registry.terraform.io/hashicorp/local v2.4.1
+ provider registry.terraform.io/hashicorp/null v3.2.2
+ provider registry.terraform.io/hashicorp/random v3.6.0
+ provider registry.terraform.io/hashicorp/tfe v0.51.1

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer setup_workspace % terraform init                                         

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/null v3.2.2

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=5986620880133676008]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "5986620880133676008" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=5986620880133676008]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/template v2.2.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v2.2.0 (unauthenticated)
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_arm64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Finding latest version of hashicorp/random...
│ - Finding latest version of hashicorp/template...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/template v2.2.0...
│ - Installed hashicorp/template v2.2.0 (unauthenticated)
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
│ │ package available for your current platform, darwin_arm64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % m1-terraform-provider-helper activate
Already activated
markusburg@computer setup_workspace % m1-terraform-provider-helper install hashicorp/template -v v2.2.0
Getting provider data from terraform registry
2024/01/18 20:11:19 Getting provider data from https://registry.terraform.io/v1/providers/hashicorp/template
2024/01/18 20:11:19 Provider data: {https://github.com/hashicorp/terraform-provider-template terraform-provider-template}
Getting source code...
2024/01/18 20:11:19 Extracted repo https://github.com/hashicorp/terraform-provider-template to terraform-provider-template
2024/01/18 20:11:19 Resetting /Users/markusburg/.m1-terraform-provider-helper/terraform-provider-template and pulling latest changes
Compiling...
Successfully installed hashicorp/template v2.2.0
markusburg@computer setup_workspace % terraform init                                                

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/null v3.2.2

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"       
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=7229922334066521075]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "7229922334066521075" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=7229922334066521075]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/template v2.2.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v2.2.0 (unauthenticated)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_arm64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Finding latest version of hashicorp/random...
│ - Finding latest version of hashicorp/template...
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/template v2.2.0...
│ - Installed hashicorp/template v2.2.0 (unauthenticated)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
│ │ package available for your current platform, darwin_arm64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % rm .terraform.lock.hcl
markusburg@computer setup_workspace % terraform init                                         

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Finding latest version of hashicorp/tfe...
- Finding latest version of hashicorp/local...
- Finding latest version of hashicorp/null...
- Finding latest version of hashicorp/random...
- Installing hashicorp/tfe v0.51.1...
- Installed hashicorp/tfe v0.51.1 (signed by HashiCorp)
- Installing hashicorp/local v2.4.1...
- Installed hashicorp/local v2.4.1 (signed by HashiCorp)
- Installing hashicorp/null v3.2.2...
- Installed hashicorp/null v3.2.2 (signed by HashiCorp)
- Installing hashicorp/random v3.6.0...
- Installed hashicorp/random v3.6.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=59721505088918266]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "59721505088918266" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=59721505088918266]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/template v2.2.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v2.2.0 (unauthenticated)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_arm64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding latest version of hashicorp/random...
│ - Finding latest version of hashicorp/template...
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/template v2.2.0...
│ - Installed hashicorp/template v2.2.0 (unauthenticated)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
│ │ package available for your current platform, darwin_arm64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % m1-terraform-provider-helper install l
Getting provider data from terraform registry
2024/01/18 20:15:11 Getting provider data from https://registry.terraform.io/v1/providers/l
FATA[0000] Error while trying to get provider data from terraform registry: parsed JSON but repo could no be determined. Got json '{"errors":["Not Found"]}' from url: 'https://registry.terraform.io/v1/providers/l' 
markusburg@computer setup_workspace % m1-terraform-provider-helper install list
Getting provider data from terraform registry
2024/01/18 20:15:15 Getting provider data from https://registry.terraform.io/v1/providers/list
FATA[0000] Error while trying to get provider data from terraform registry: parsed JSON but repo could no be determined. Got json '{"errors":["Not Found"]}' from url: 'https://registry.terraform.io/v1/providers/list' 
markusburg@computer setup_workspace % m1-terraform-provider-helper install search
Getting provider data from terraform registry
2024/01/18 20:15:20 Getting provider data from https://registry.terraform.io/v1/providers/search
FATA[0000] Error while trying to get provider data from terraform registry: parsed JSON but repo could no be determined. Got json '{"errors":["Not Found"]}' from url: 'https://registry.terraform.io/v1/providers/search' 
markusburg@computer setup_workspace % m1-terraform-provider-helper list          
hashicorp/template -> 2.2.0
markusburg@computer setup_workspace % m1-terraform-provider-helper install hashicorp/template -v v2.2.0m1-terraform-provider-helper lockfile upgrade
markusburg@computer setup_workspace % 
markusburg@computer setup_workspace % 
markusburg@computer setup_workspace % m1-terraform-provider-helper lockfile upgrade
2024/01/18 20:18:25 Lockfile path: .terraform.lock.hcl
2024/01/18 20:18:25 Output path: .terraform.lock.hcl
markusburg@computer setup_workspace % m1-terraform-provider-helper uninstall                 
Error: unknown command "uninstall" for "m1-terraform-provider-helper"

Did you mean this?
	install

Run 'm1-terraform-provider-helper --help' for usage.
2024/01/18 20:19:58 unknown command "uninstall" for "m1-terraform-provider-helper"

Did you mean this?
	install
markusburg@computer setup_workspace % brew uninstall m1-terraform-provider-helper
Uninstalling /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0... (6 files, 12.8MB)
markusburg@computer setup_workspace % brew uninstall terraform 
Error: No such keg: /opt/homebrew/Cellar/terraform
markusburg@computer setup_workspace % brew install tfenv
==> Downloading https://formulae.brew.sh/api/formula.jws.json
##O=#     #                                                                                                                                                            
==> Downloading https://formulae.brew.sh/api/cask.jws.json
##O=#     #                                                                                                                                                            
==> Downloading https://ghcr.io/v2/homebrew/core/tfenv/manifests/3.0.0
################################################################################################################################################################# 100.0%
==> Fetching dependencies for tfenv: pcre2 and grep
==> Downloading https://ghcr.io/v2/homebrew/core/pcre2/manifests/10.42
################################################################################################################################################################# 100.0%
==> Fetching pcre2
==> Downloading https://ghcr.io/v2/homebrew/core/pcre2/blobs/sha256:f9abacbf5d8f637449706d2bc3ed80c4d25963c014fcb5bea5bc9e5828badef0
################################################################################################################################################################# 100.0%
==> Downloading https://ghcr.io/v2/homebrew/core/grep/manifests/3.11
################################################################################################################################################################# 100.0%
==> Fetching grep
==> Downloading https://ghcr.io/v2/homebrew/core/grep/blobs/sha256:0c5a74551504781dec17477fd6a7ec21680c3b30be3f421d02e4f57593181ad2
################################################################################################################################################################# 100.0%
==> Fetching tfenv
==> Downloading https://ghcr.io/v2/homebrew/core/tfenv/blobs/sha256:4905c2390b0254348be44da1c4a05b3d8bf4d8704b94d16b739d64fd4709784b
################################################################################################################################################################# 100.0%
==> Installing dependencies for tfenv: pcre2 and grep
==> Installing tfenv dependency: pcre2
==> Downloading https://ghcr.io/v2/homebrew/core/pcre2/manifests/10.42
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/6a53794fcaabc5cc5e05b19c02ca9c4c5f2cb9a4d65a5790a6841146465b040f--pcre2-10.42.bottle_manifest.json
==> Pouring pcre2--10.42.arm64_sonoma.bottle.tar.gz
🍺  /opt/homebrew/Cellar/pcre2/10.42: 230 files, 6.1MB
==> Installing tfenv dependency: grep
==> Downloading https://ghcr.io/v2/homebrew/core/grep/manifests/3.11
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/e0582271986bf91f2f8f4af389bbff336bb2e5cdcc91dd33fd2b4b3e42a37afe--grep-3.11.bottle_manifest.json
==> Pouring grep--3.11.arm64_sonoma.bottle.tar.gz
🍺  /opt/homebrew/Cellar/grep/3.11: 19 files, 1MB
==> Installing tfenv
==> Pouring tfenv--3.0.0.all.bottle.tar.gz
🍺  /opt/homebrew/Cellar/tfenv/3.0.0: 28 files, 98.8KB
==> Running `brew cleanup tfenv`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer setup_workspace % TFENV_ARCH=amd64 tfenv install 1.7.0
Installing Terraform v1.7.0
Downloading release tarball from https://releases.hashicorp.com/terraform/1.7.0/terraform_1.7.0_darwin_amd64.zip
################################################################################################################################################################# 100.0%
Downloading SHA hash file from https://releases.hashicorp.com/terraform/1.7.0/terraform_1.7.0_SHA256SUMS
Not instructed to use Local PGP (/opt/homebrew/Cellar/tfenv/3.0.0/use-{gpgv,gnupg}) & No keybase install found, skipping OpenPGP signature verification
Archive:  /var/folders/f0/jhh6hsrd36g9_lwxt6h8506r0000gn/T/tfenv_download.XXXXXX.ouQrA2BeEc/terraform_1.7.0_darwin_amd64.zip
  inflating: /opt/homebrew/Cellar/tfenv/3.0.0/versions/1.7.0/terraform  
Installation of terraform v1.7.0 successful. To make this your default version, run 'tfenv use 1.7.0'
markusburg@computer setup_workspace % tfenv use 1.7.0
Switching default version to v1.7.0
Default version (when not overridden by .terraform-version or TFENV_TERRAFORM_VERSION) is now: 1.7.0
markusburg@computer setup_workspace % terraform init                                         

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/null v3.2.2
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/local v2.4.1

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=5204717132081227148]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "5204717132081227148" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=5204717132081227148]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit: Still creating... [10s elapsed]
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/awscc v0.8.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/awscc v0.8.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/template v2.2.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_amd64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding latest version of hashicorp/random...
│ - Finding latest version of hashicorp/template...
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/awscc v0.8.0...
│ - Installed hashicorp/awscc v0.8.0 (signed by HashiCorp)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/template v2.2.0 does not have a
│ │ package available for your current platform, darwin_amd64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % m1-terraform-provider-helper uninstall hashicorp/template -v v2.2.0
zsh: command not found: m1-terraform-provider-helper
markusburg@computer setup_workspace % brew install m1-terraform-provider-helper 
==> Fetching kreuzwerker/taps/m1-terraform-provider-helper
==> Downloading https://github.com/kreuzwerker/m1-terraform-provider-helper/releases/download/0.9.0/m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/0452e3a4a0e2aabeaedbabdd93ddfbb22d29dddd703ecb2e28498beb50897cd9--m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
==> Installing m1-terraform-provider-helper from kreuzwerker/taps
🍺  /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0: 6 files, 12.8MB, built in 1 second
==> Running `brew cleanup m1-terraform-provider-helper`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer setup_workspace % m1-terraform-provider-helper uninstall hashicorp/template -v v2.2.0
Error: unknown command "uninstall" for "m1-terraform-provider-helper"

Did you mean this?
	install

Run 'm1-terraform-provider-helper --help' for usage.
2024/01/18 20:24:06 unknown command "uninstall" for "m1-terraform-provider-helper"

Did you mean this?
	install
markusburg@computer setup_workspace % brew uninstall m1-terraform-provider-helper      
Uninstalling /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0... (6 files, 12.8MB)
markusburg@computer setup_workspace % m1-terraform-provider-helper uninstall hashicorp/template -v v3.22.0
zsh: command not found: m1-terraform-provider-helper
markusburg@computer setup_workspace % brew install m1-terraform-provider-helper                          
==> Downloading https://formulae.brew.sh/api/formula.jws.json
#=#=- #     #                                                                                                                                                          
==> Downloading https://formulae.brew.sh/api/cask.jws.json
#=#=- #     #                                                                                                                                                          
==> Fetching kreuzwerker/taps/m1-terraform-provider-helper
==> Downloading https://github.com/kreuzwerker/m1-terraform-provider-helper/releases/download/0.9.0/m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/0452e3a4a0e2aabeaedbabdd93ddfbb22d29dddd703ecb2e28498beb50897cd9--m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
==> Installing m1-terraform-provider-helper from kreuzwerker/taps
🍺  /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0: 6 files, 12.8MB, built in 1 second
==> Running `brew cleanup m1-terraform-provider-helper`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer setup_workspace % m1-terraform-provider-helper uninstall hashicorp/template -v v3.22.0
Error: unknown command "uninstall" for "m1-terraform-provider-helper"

Did you mean this?
	install

Run 'm1-terraform-provider-helper --help' for usage.
2024/01/18 20:30:53 unknown command "uninstall" for "m1-terraform-provider-helper"

Did you mean this?
	install
markusburg@computer setup_workspace % m1-terraform-provider-helper install hashicorp/template -v v3.22.0 
Getting provider data from terraform registry
2024/01/18 20:31:06 Getting provider data from https://registry.terraform.io/v1/providers/hashicorp/template
2024/01/18 20:31:06 Provider data: {https://github.com/hashicorp/terraform-provider-template terraform-provider-template}
Getting source code...
2024/01/18 20:31:06 Extracted repo https://github.com/hashicorp/terraform-provider-template to terraform-provider-template
2024/01/18 20:31:06 Resetting /Users/markusburg/.m1-terraform-provider-helper/terraform-provider-template and pulling latest changes
Compiling...
Successfully installed hashicorp/template v3.22.0
markusburg@computer setup_workspace % brew uninstall m1-terraform-provider-helper                         
Uninstalling /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0... (6 files, 12.8MB)
markusburg@computer setup_workspace % eraform -v
zsh: command not found: eraform
markusburg@computer setup_workspace % terraform -v
Terraform v1.6.6
on darwin_arm64
+ provider registry.terraform.io/hashicorp/local v2.4.1
+ provider registry.terraform.io/hashicorp/null v3.2.2
+ provider registry.terraform.io/hashicorp/random v3.6.0
+ provider registry.terraform.io/hashicorp/tfe v0.51.1

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer setup_workspace % terraform init                                                     

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Using previously-installed hashicorp/null v3.2.2
- Using previously-installed hashicorp/local v2.4.1
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/random v3.6.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"            
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=718581881471694855]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "718581881471694855" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=718581881471694855]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/awscc v0.8.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/awscc v0.8.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/template v3.22.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_amd64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding latest version of hashicorp/template...
│ - Finding latest version of hashicorp/random...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/awscc v0.8.0...
│ - Installed hashicorp/awscc v0.8.0 (signed by HashiCorp)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/template v3.22.0 does not have a
│ │ package available for your current platform, darwin_amd64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % brew install m1-terraform-provider-helper                           
==> Fetching kreuzwerker/taps/m1-terraform-provider-helper
==> Downloading https://github.com/kreuzwerker/m1-terraform-provider-helper/releases/download/0.9.0/m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/0452e3a4a0e2aabeaedbabdd93ddfbb22d29dddd703ecb2e28498beb50897cd9--m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
==> Installing m1-terraform-provider-helper from kreuzwerker/taps
🍺  /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0: 6 files, 12.8MB, built in 1 second
==> Running `brew cleanup m1-terraform-provider-helper`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer setup_workspace % terraform -v                                           
Terraform v1.6.6
on darwin_arm64
+ provider registry.terraform.io/hashicorp/local v2.4.1
+ provider registry.terraform.io/hashicorp/null v3.2.2
+ provider registry.terraform.io/hashicorp/random v3.6.0
+ provider registry.terraform.io/hashicorp/tfe v0.51.1

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer setup_workspace % brew uninstall tfenv                             
Uninstalling /opt/homebrew/Cellar/tfenv/3.0.0... (30 files, 90.9MB)
markusburg@computer setup_workspace % terraform -v                             
Terraform v1.6.6
on darwin_arm64
+ provider registry.terraform.io/hashicorp/local v2.4.1
+ provider registry.terraform.io/hashicorp/null v3.2.2
+ provider registry.terraform.io/hashicorp/random v3.6.0
+ provider registry.terraform.io/hashicorp/tfe v0.51.1

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer setup_workspace % brew install m1-terraform-provider-helper
Warning: kreuzwerker/taps/m1-terraform-provider-helper 0.9.0 is already installed and up-to-date.
To reinstall 0.9.0, run:
  brew reinstall m1-terraform-provider-helper
markusburg@computer setup_workspace % brew uninstall terraform
Error: No such keg: /opt/homebrew/Cellar/terraform
markusburg@computer setup_workspace % brew reinstall m1-terraform-provider-helper
==> Fetching kreuzwerker/taps/m1-terraform-provider-helper
==> Downloading https://github.com/kreuzwerker/m1-terraform-provider-helper/releases/download/0.9.0/m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
Already downloaded: /Users/markusburg/Library/Caches/Homebrew/downloads/0452e3a4a0e2aabeaedbabdd93ddfbb22d29dddd703ecb2e28498beb50897cd9--m1-terraform-provider-helper_0.9.0_Darwin_arm64.tar.gz
==> Reinstalling kreuzwerker/taps/m1-terraform-provider-helper 
🍺  /opt/homebrew/Cellar/m1-terraform-provider-helper/0.9.0: 6 files, 12.8MB, built in 1 second
==> Running `brew cleanup m1-terraform-provider-helper`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
markusburg@computer setup_workspace % terraform -v                             
Terraform v1.6.6
on darwin_arm64
+ provider registry.terraform.io/hashicorp/local v2.4.1
+ provider registry.terraform.io/hashicorp/null v3.2.2
+ provider registry.terraform.io/hashicorp/random v3.6.0
+ provider registry.terraform.io/hashicorp/tfe v0.51.1

Your version of Terraform is out of date! The latest version
is 1.7.0. You can update by downloading from https://www.terraform.io/downloads.html
markusburg@computer setup_workspace % brew update m1-terraform-provider-helper latest
Error: This command updates brew itself, and does not take formula names.
Use `brew upgrade m1-terraform-provider-helper latest` instead.
markusburg@computer setup_workspace % brew upgrade m1-terraform-provider-helper latest
==> Downloading https://formulae.brew.sh/api/formula.jws.json

==> Downloading https://formulae.brew.sh/api/cask.jws.json

Warning: kreuzwerker/taps/m1-terraform-provider-helper 0.9.0 already installed
Error: Cask 'latest' is not installed.
markusburg@computer setup_workspace % terraform init                                         

Initializing the backend...
Initializing modules...

Initializing provider plugins...
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/tfe from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Using previously-installed hashicorp/null v3.2.2
- Using previously-installed hashicorp/tfe v0.51.1
- Using previously-installed hashicorp/random v3.6.0
- Using previously-installed hashicorp/local v2.4.1

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=5098297000663298885]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "5098297000663298885" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=5098297000663298885]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/template v3.22.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v3.22.0 (unauthenticated)
null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Error: Incompatible provider version
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
null_resource.remoteinit (local-exec): │ package available for your current platform, darwin_arm64.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Provider releases are separate from Terraform CLI releases, so not all
null_resource.remoteinit (local-exec): │ providers are available for all platforms. Other versions of this provider
null_resource.remoteinit (local-exec): │ may have different platforms supported.
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
╷
│ Error: local-exec provisioner error
│ 
│   with null_resource.remoteinit,
│   on workspace.tf line 35, in resource "null_resource" "remoteinit":
│   35:   provisioner "local-exec" {
│ 
│ Error running command 'terraform init -backend-config=backend.hcl': exit status 1. Output: 
│ Initializing the backend...
│ Initializing modules...
│ 
│ Initializing provider plugins...
│ - Finding latest version of hashicorp/template...
│ - Finding latest version of hashicorp/random...
│ - Finding hashicorp/aws versions matching "3.66.0"...
│ - Finding hashicorp/awscc versions matching "0.8.0"...
│ - Installing hashicorp/random v3.6.0...
│ - Installed hashicorp/random v3.6.0 (signed by HashiCorp)
│ - Installing hashicorp/aws v3.66.0...
│ - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
│ - Installing hashicorp/template v3.22.0...
│ - Installed hashicorp/template v3.22.0 (unauthenticated)
│ ╷
│ │ Error: Incompatible provider version
│ │ 
│ │ Provider registry.terraform.io/hashicorp/awscc v0.8.0 does not have a
│ │ package available for your current platform, darwin_arm64.
│ │ 
│ │ Provider releases are separate from Terraform CLI releases, so not all
│ │ providers are available for all platforms. Other versions of this provider
│ │ may have different platforms supported.
│ ╵
│ 
│ 
╵
markusburg@computer setup_workspace % m1-terraform-provider-helper install -v hashicorp/awscc v0.8.0
Getting provider data from terraform registry
2024/01/18 20:40:01 Getting provider data from https://registry.terraform.io/v1/providers/v0.8.0
FATA[0000] Error while trying to get provider data from terraform registry: parsed JSON but repo could no be determined. Got json '{"errors":["Not Found"]}' from url: 'https://registry.terraform.io/v1/providers/v0.8.0' 
markusburg@computer setup_workspace % m1-terraform-provider-helper install hashicorp/awscc -v v0.8.0
Getting provider data from terraform registry
2024/01/18 20:40:21 Getting provider data from https://registry.terraform.io/v1/providers/hashicorp/awscc
2024/01/18 20:40:22 Provider data: {https://github.com/hashicorp/terraform-provider-awscc terraform-provider-awscc}
Getting source code...
2024/01/18 20:40:22 Extracted repo https://github.com/hashicorp/terraform-provider-awscc to terraform-provider-awscc
2024/01/18 20:40:22 Cloning https://github.com/hashicorp/terraform-provider-awscc to /Users/markusburg/.m1-terraform-provider-helper/terraform-provider-awscc
Enumerating objects: 73562, done.
Counting objects: 100% (650/650), done.
Compressing objects: 100% (233/233), done.
Total 73562 (delta 421), reused 624 (delta 403), pack-reused 72912
2024/01/18 20:40:31 Resetting /Users/markusburg/.m1-terraform-provider-helper/terraform-provider-awscc and pulling latest changes
Compiling...
Successfully installed hashicorp/awscc v0.8.0
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"       
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=8006361041583681993]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # null_resource.remoteinit is tainted, so must be replaced
-/+ resource "null_resource" "remoteinit" {
      ~ id = "8006361041583681993" -> (known after apply)
    }

Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

null_resource.remoteinit: Destroying... [id=8006361041583681993]
null_resource.remoteinit: Destruction complete after 0s
null_resource.remoteinit: Creating...
null_resource.remoteinit: Provisioning with 'local-exec'...
null_resource.remoteinit (local-exec): Executing: ["/bin/sh" "-c" "terraform init -backend-config=backend.hcl"]

null_resource.remoteinit (local-exec): Initializing the backend...
null_resource.remoteinit (local-exec): Initializing modules...

null_resource.remoteinit (local-exec): Initializing provider plugins...
null_resource.remoteinit (local-exec): - Finding hashicorp/aws versions matching "3.66.0"...
null_resource.remoteinit (local-exec): - Finding hashicorp/awscc versions matching "0.8.0"...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/random...
null_resource.remoteinit (local-exec): - Finding latest version of hashicorp/template...
null_resource.remoteinit (local-exec): - Installing hashicorp/template v3.22.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/template v3.22.0 (unauthenticated)
null_resource.remoteinit (local-exec): - Installing hashicorp/aws v3.66.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/aws v3.66.0 (signed by HashiCorp)
null_resource.remoteinit (local-exec): - Installing hashicorp/awscc v0.8.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/awscc v0.8.0 (unauthenticated)
null_resource.remoteinit (local-exec): - Installing hashicorp/random v3.6.0...
null_resource.remoteinit (local-exec): - Installed hashicorp/random v3.6.0 (signed by HashiCorp)

null_resource.remoteinit (local-exec): Terraform has created a lock file .terraform.lock.hcl to record the provider
null_resource.remoteinit (local-exec): selections it made above. Include this file in your version control repository
null_resource.remoteinit (local-exec): so that Terraform can guarantee to make the same selections by default when
null_resource.remoteinit (local-exec): you run "terraform init" in the future.

null_resource.remoteinit (local-exec): ╷
null_resource.remoteinit (local-exec): │ Warning: Incomplete lock file information for providers
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ Due to your customized provider installation methods, Terraform was forced
null_resource.remoteinit (local-exec): │ to calculate lock file checksums locally for the following providers:
null_resource.remoteinit (local-exec): │   - hashicorp/awscc
null_resource.remoteinit (local-exec): │   - hashicorp/template
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ The current .terraform.lock.hcl file only includes checksums for
null_resource.remoteinit (local-exec): │ darwin_arm64, so Terraform running on another platform will fail to install
null_resource.remoteinit (local-exec): │ these providers.
null_resource.remoteinit (local-exec): │ 
null_resource.remoteinit (local-exec): │ To calculate additional checksums for another platform, run:
null_resource.remoteinit (local-exec): │   terraform providers lock -platform=linux_amd64
null_resource.remoteinit (local-exec): │ (where linux_amd64 is the platform to generate)
null_resource.remoteinit (local-exec): ╵
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): Terraform has been successfully initialized!
null_resource.remoteinit (local-exec): 
null_resource.remoteinit (local-exec): You may now begin working with Terraform. Try running "terraform plan" to see
null_resource.remoteinit (local-exec): any changes that are required for your infrastructure. All Terraform commands
null_resource.remoteinit (local-exec): should now work.

null_resource.remoteinit (local-exec): If you ever set or change modules or backend configuration for Terraform,
null_resource.remoteinit (local-exec): rerun this command to reinitialize your working directory. If you forget, other
null_resource.remoteinit (local-exec): commands will detect it and remind you to do so if necessary.
null_resource.remoteinit: Creation complete after 6s [id=7188597471027504236]

Apply complete! Resources: 1 added, 0 changed, 1 destroyed.

Outputs:

user_instructions = <<EOT
# org name    = tudublin
# workspace   = w-aws-ia-mtpmlv


# Run these commands in order:
cd ../deploy

# Configure your tfvars file
  AWS_SECRET_ACCESS_KEY = "*****************"
  AWS_ACCESS_KEY_ID     = "*****************"
  AWS_SESSION_TOKEN     = "*****************"
  region                = eu-west-1

#  Note: Use of STS Creds are highly reccommended!
# !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
# (and follow secrets mangement bestpractices)
#   
   terraform apply  -var-file="$HOME/.aws/terraform.tfvars"

EOT
markusburg@computer setup_workspace % terraform apply
var.AWS_ACCESS_KEY_ID
  Enter a value: AKIAWYELJ4WJTLRM4Z4W

var.AWS_SECRET_ACCESS_KEY
  Enter a value: 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

var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=7188597471027504236]

No changes. Your infrastructure matches the configuration.

Terraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

user_instructions = <<EOT
# org name    = tudublin
# workspace   = w-aws-ia-mtpmlv


# Run these commands in order:
cd ../deploy

# Configure your tfvars file
  AWS_SECRET_ACCESS_KEY = "*****************"
  AWS_ACCESS_KEY_ID     = "*****************"
  AWS_SESSION_TOKEN     = "*****************"
  region                = eu-west-1

#  Note: Use of STS Creds are highly reccommended!
# !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
# (and follow secrets mangement bestpractices)
#   
   terraform apply  -var-file="$HOME/.aws/terraform.tfvars"

EOT
markusburg@computer setup_workspace % terraform apply -var-file="$HOME/.aws/terraform.tfvars"
var.region
  Enter a value: eu-west-1

var.tfe_organization
  Enter a value: tudublin

module.tfcloud.random_string.rand8: Refreshing state... [id=9m8qb96a]
module.tfcloud.random_string.rand6: Refreshing state... [id=mtpmlv]
module.tfcloud.tfe_workspace.tf-ws: Refreshing state... [id=ws-TTzUWjfLWbdohkBA]
module.tfcloud.local_file.backend_file: Refreshing state... [id=23b238b74f8c2d4e406237f27eb4f6825610ee6a]
module.tfcloud.tfe_variable.AWS_ACCESS_KEY_ID: Refreshing state... [id=var-oWCRSq1hnBRhDQ9B]
module.tfcloud.tfe_variable.region: Refreshing state... [id=var-ESaZZgMSBqYjq4Ei]
module.tfcloud.tfe_variable.AWS_SECRET_ACCESS_KEY: Refreshing state... [id=var-9JbGzyRk5VK2GQm4]
null_resource.setup_backend_file: Refreshing state... [id=5430304601694551473]
null_resource.remoteinit: Refreshing state... [id=7188597471027504236]

No changes. Your infrastructure matches the configuration.

Terraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

user_instructions = <<EOT
# org name    = tudublin
# workspace   = w-aws-ia-mtpmlv


# Run these commands in order:
cd ../deploy

# Configure your tfvars file
  AWS_SECRET_ACCESS_KEY = "*****************"
  AWS_ACCESS_KEY_ID     = "*****************"
  AWS_SESSION_TOKEN     = "*****************"
  region                = eu-west-1

#  Note: Use of STS Creds are highly reccommended!
# !!!!CAUTION!!!!: Make sure your credentials are secured outside version control 
# (and follow secrets mangement bestpractices)
#   
   terraform apply  -var-file="$HOME/.aws/terraform.tfvars"

EOT
markusburg@computer setup_workspace % 
